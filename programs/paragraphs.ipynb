{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"right\" src=\"images/dans-small.png\"/>\n",
    "<img align=\"right\" src=\"images/tf-small.png\"/>\n",
    "<img align=\"right\" src=\"images/etcbc.png\"/>\n",
    "\n",
    "\n",
    "# Paragraphs\n",
    "\n",
    "This notebook can read ETCBC `.px` files with information\n",
    "about *paragraphs* in it.\n",
    "We distill a bunch of extra features at the `clause_atom` level, namely:\n",
    "* `pargr`\n",
    "* `instruction`\n",
    "\n",
    "**NB** This conversion will not work for versions `4` and `4b`.\n",
    "\n",
    "## Discussion\n",
    "Somebody should tell in more detail what they are, and document it in the feature documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os,sys,re,collections\n",
    "from tf.fabric import Fabric\n",
    "from tf.transcription import Transcription\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline\n",
    "See [operation](https://github.com/ETCBC/pipeline/blob/master/README.md#operation) \n",
    "for how to run this script in the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if 'SCRIPT' not in locals():\n",
    "    SCRIPT = False\n",
    "    FORCE = True\n",
    "    CORE_NAME = 'bhsa'\n",
    "    VERSION= 'c'\n",
    "\n",
    "def stop(good=False):\n",
    "    if SCRIPT: sys.exit(0 if good else 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up the context: source file and target directories\n",
    "\n",
    "The conversion is executed in an environment of directories, so that sources, temp files and\n",
    "results are in convenient places and do not have to be shifted around."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "repoBase = os.path.expanduser('~/github/etcbc')\n",
    "thisRepo = '{}/{}'.format(repoBase, CORE_NAME)\n",
    "\n",
    "thisSource = '{}/source/{}'.format(thisRepo, VERSION)\n",
    "\n",
    "thisTemp = '{}/_temp/{}'.format(thisRepo, VERSION)\n",
    "thisTempSource = '{}/source'.format(thisTemp)\n",
    "thisTempTf = '{}/tf'.format(thisTemp)\n",
    "\n",
    "thisTf = '{}/tf/{}'.format(thisRepo, VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testFeature = 'pargr'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test\n",
    "\n",
    "Check whether this conversion is needed in the first place.\n",
    "Only when run as a script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if SCRIPT:\n",
    "    (good, work) = utils.mustRun(None, '{}/.tf/{}.tfx'.format(thisTf, testFeature), force=FORCE)\n",
    "    if not good: stop(good=False)\n",
    "    if not work: stop(good=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF Settings\n",
    "\n",
    "* a piece of metadata that will go into these features; the time will be added automatically\n",
    "* new text formats for the `otext` feature of TF, based on lexical features.\n",
    "  We select the version specific otext material, \n",
    "  falling back on a default if nothing appropriate has been specified in oText.\n",
    " \n",
    "We do not do this for the older versions `4` and `4b`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "provenanceMetadata = dict(\n",
    "    dataset='BHSA',\n",
    "    datasetName='Biblia Hebraica Stuttgartensia Amstelodamensis',\n",
    "    version=VERSION,\n",
    "    author='Eep Talstra Centre for Bible and Computer',\n",
    "    encoders='Constantijn Sikkel (QDF), and Dirk Roorda (TF)',\n",
    "    website='https://shebanq.ancient-data.org',\n",
    "    email='shebanq@ancient-data.org',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................................................................................\n",
      ".       0.00s Load the existing TF dataset                                                   .\n",
      "..............................................................................................\n",
      "This is Text-Fabric 3.0.2\n",
      "Api reference : https://github.com/Dans-labs/text-fabric/wiki/Api\n",
      "Tutorial      : https://github.com/Dans-labs/text-fabric/blob/master/docs/tutorial.ipynb\n",
      "Example data  : https://github.com/Dans-labs/text-fabric-data\n",
      "\n",
      "99 features found and 0 ignored\n",
      "  0.00s loading features ...\n",
      "   |     0.02s B label                from /Users/dirk/github/etcbc/bhsa/tf/c\n",
      "   |     0.30s B number               from /Users/dirk/github/etcbc/bhsa/tf/c\n",
      "   |     0.00s Feature overview: 94 for nodes; 4 for edges; 1 configs; 7 computed\n",
      "  6.07s All features loaded/computed - for details use loadLog()\n"
     ]
    }
   ],
   "source": [
    "utils.caption(4, 'Load the existing TF dataset')\n",
    "TF = Fabric(locations=thisTf, modules=[''])\n",
    "api = TF.load('label number')\n",
    "api.makeAvailableIn(globals())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clause atom identifiers in .px\n",
    "We must map the way the clause_atoms are identified in the `.px` files\n",
    "to nodes in TF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|       6.14s \tLabeling clause_atoms\n",
      "|       8.58s \tOK: clause atoms succesfully labeled\n",
      "|       8.58s \t90562 clause atoms\n"
     ]
    }
   ],
   "source": [
    "utils.caption(0, '\\tLabeling clause_atoms')\n",
    "\n",
    "labelNumberFromNode = {}\n",
    "nodeFromLabelNumber = {}\n",
    "for n in N():\n",
    "    otype = F.otype.v(n)\n",
    "    if otype == 'book':\n",
    "        curSubtract = 0\n",
    "        curChapterSeq = 0\n",
    "    elif otype == 'chapter':\n",
    "        curSubtract += curChapterSeq\n",
    "        curChapterSeq = 0\n",
    "    elif otype == 'verse':\n",
    "        curLabel = F.label.v(n)\n",
    "    elif otype == 'clause_atom':\n",
    "        curChapterSeq += 1\n",
    "        nm = int(F.number.v(n)) - curSubtract\n",
    "        nodeFromLabelNumber[(curLabel, nm)] = n\n",
    "        labelNumberFromNode[n] = (curLabel, nm)\n",
    "\n",
    "nLabs = len(nodeFromLabelNumber)\n",
    "nNodes = len(labelNumberFromNode)\n",
    "\n",
    "if nLabs == nNodes:\n",
    "    utils.caption(0, '\\tOK: clause atoms succesfully labeled')\n",
    "    utils.caption(0, '\\t{} clause atoms'.format(nNodes))\n",
    "else:\n",
    "    utils.caption(0, '\\tWARNING: clause atoms not uniquely labeled')\n",
    "    utils.caption(0, '\\t{} labels =/= {} nodes'.format(nLabs, nNodes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the PX files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................................................................................\n",
      ".       8.70s Parsing paragraph data in PX                                                   .\n",
      "..............................................................................................\n",
      "|       8.70s bunzipping /Users/dirk/github/etcbc/bhsa/source/c/paragraphs.txt.bz2 ...\n",
      "|       8.70s \tNOTE: Using existing unzipped file which is newer than bzipped one\n",
      "|       9.80s \tRead 90562 paragraph annotations\n",
      "|       9.80s \tOK: All label/line entries found in index\n"
     ]
    }
   ],
   "source": [
    "utils.caption(4, 'Parsing paragraph data in PX')\n",
    "\n",
    "pxFile = '{}/paragraphs.txt'.format(thisTempSource)\n",
    "pxzFile = '{}/paragraphs.txt.bz2'.format(thisSource)\n",
    "utils.caption(0, 'bunzipping {} ...'.format(pxzFile))\n",
    "utils.bunzip(pxzFile, pxFile)\n",
    "pxHandle = open(pxFile)\n",
    "\n",
    "data = []\n",
    "notFound = set()\n",
    "\n",
    "ln = 0\n",
    "can = 0\n",
    "featurescan = re.compile(r'0 0 (..) [0-9]+ LineNr\\s*([0-9]+).*?Pargr:\\s*([0-9.]+)')\n",
    "curLabel = None\n",
    "\n",
    "for line in pxHandle:\n",
    "    ln += 1\n",
    "    if line.strip()[0] != '*':\n",
    "        curLabel = line[0:10]\n",
    "        continue\n",
    "    can += 1\n",
    "    features = featurescan.findall(line)\n",
    "    if len(features) == 0:\n",
    "        utils.caption(0, '\\tWarning: line {}: no instruction, LineNr, Pargr found'.format(ln))\n",
    "    elif len(features) > 1:\n",
    "        utils.caption(0, '\\tWarning: line {}: multiple instruction, LineNr, Pargr found'.format(ln))\n",
    "    else:\n",
    "        feature = features[0]\n",
    "        theIns = feature[0]\n",
    "        theN = feature[1]\n",
    "        thePara = feature[2]\n",
    "        labNum = (curLabel, int(theN))\n",
    "        if labNum not in nodeFromLabelNumber:\n",
    "            notFound.add(labNum)\n",
    "            continue\n",
    "        data.append((nodeFromLabelNumber[labNum], theIns, theN, thePara))\n",
    "pxHandle.close()\n",
    "utils.caption(0, '\\tRead {} paragraph annotations'.format(len(data)))\n",
    "\n",
    "if notFound:\n",
    "    utils.caption(0, '\\tWARNING: Could not find {} label/line entries in index: {}'.format(\n",
    "        len(notFound), sorted({lab for lab in notFound}),\n",
    "    ))\n",
    "else:\n",
    "    utils.caption(0, '\\tOK: All label/line entries found in index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(576266, '.N', '1', '1')\n",
      "(576267, '..', '2', '1')\n",
      "(576268, '..', '3', '1')\n",
      "(576269, '..', '4', '1')\n",
      "(576270, '.q', '5', '1.1')\n",
      "(576271, '..', '6', '1.1')\n",
      "(576272, '..', '7', '1.1')\n",
      "(576273, '..', '8', '1.1')\n",
      "(576274, '..', '9', '1.1')\n",
      "(576275, '.q', '10', '1.1.1')\n"
     ]
    }
   ],
   "source": [
    "if not SCRIPT:\n",
    "    print('\\n'.join(repr(d) for d in data[0:10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare TF features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|       9.84s Prepare TF paragraph features\n"
     ]
    }
   ],
   "source": [
    "utils.caption(0, 'Prepare TF paragraph features')\n",
    "\n",
    "metaData = {}\n",
    "nodeFeatures = {}\n",
    "\n",
    "newFeatures = '''\n",
    "    pargr\n",
    "    instruction\n",
    "'''.strip().split()\n",
    "\n",
    "nodeFeatures = dict( \n",
    "    instruction=dict(((x[0], x[1]) for x in data)),\n",
    "    pargr=dict(((x[0], x[3]) for x in data)),\n",
    ")\n",
    "\n",
    "for f in nodeFeatures:\n",
    "    metaData[f] = {}\n",
    "    metaData[f].update(provenanceMetadata)\n",
    "    metaData[f]['valueType'] = 'str'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "changedFeatures = set(nodeFeatures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write new features\n",
    "Transform the collected information in feature-like data-structures, and write it all\n",
    "out to `.tf` files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................................................................................\n",
      ".       9.93s write new/changed features to TF ...                                           .\n",
      "..............................................................................................\n",
      "   |     0.17s T instruction          to /Users/dirk/github/etcbc/bhsa/_temp/c/tf\n",
      "   |     0.17s T pargr                to /Users/dirk/github/etcbc/bhsa/_temp/c/tf\n"
     ]
    }
   ],
   "source": [
    "utils.caption(4, 'write new/changed features to TF ...')\n",
    "TF = Fabric(locations=thisTempTf, silent=True)\n",
    "TF.save(nodeFeatures=nodeFeatures, edgeFeatures={}, metaData=metaData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diffs\n",
    "\n",
    "Check differences with previous versions.\n",
    "\n",
    "The new dataset has been created in a temporary directory,\n",
    "and has not yet been copied to its destination.\n",
    "\n",
    "Here is your opportunity to compare the newly created features with the older features.\n",
    "You expect some differences in some features.\n",
    "\n",
    "We check the differences between the previous version of the features and what has been generated.\n",
    "We list features that will be added and deleted and changed.\n",
    "For each changed feature we show the first line where the new feature differs from the old one.\n",
    "We ignore changes in the metadata, because the timestamp in the metadata will always change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................................................................................\n",
      ".         10s Check differences with previous version                                        .\n",
      "..............................................................................................\n",
      "|         10s \t2 features to add\n",
      "|         10s \t\tinstruction\n",
      "|         10s \t\tpargr\n",
      "|         10s \tno features to delete\n",
      "|         10s \t0 features in common\n",
      "|         10s Done\n"
     ]
    }
   ],
   "source": [
    "utils.checkDiffs(thisTempTf, thisTf, only=changedFeatures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deliver \n",
    "\n",
    "Copy the new TF dataset from the temporary location where it has been created to its final destination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................................................................................\n",
      ".         10s Deliver features to /Users/dirk/github/etcbc/bhsa/tf/c                         .\n",
      "..............................................................................................\n",
      "|         10s \tinstruction\n",
      "|         10s \tpargr\n"
     ]
    }
   ],
   "source": [
    "utils.deliverFeatures(thisTempTf, thisTf, changedFeatures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile TF\n",
    "\n",
    "We load the new features, use the new format, check some values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................................................................................\n",
      ".         10s Load and compile the new TF features                                           .\n",
      "..............................................................................................\n",
      "This is Text-Fabric 3.0.2\n",
      "Api reference : https://github.com/Dans-labs/text-fabric/wiki/Api\n",
      "Tutorial      : https://github.com/Dans-labs/text-fabric/blob/master/docs/tutorial.ipynb\n",
      "Example data  : https://github.com/Dans-labs/text-fabric-data\n",
      "\n",
      "101 features found and 0 ignored\n",
      "  0.00s loading features ...\n",
      "   |     0.39s T instruction          from /Users/dirk/github/etcbc/bhsa/tf/c\n",
      "   |     0.40s T pargr                from /Users/dirk/github/etcbc/bhsa/tf/c\n",
      "   |     0.00s Feature overview: 96 for nodes; 4 for edges; 1 configs; 7 computed\n",
      "  8.34s All features loaded/computed - for details use loadLog()\n"
     ]
    }
   ],
   "source": [
    "utils.caption(4, 'Load and compile the new TF features')\n",
    "\n",
    "TF = Fabric(locations=thisTf, modules=[''])\n",
    "api = TF.load(' '.join(changedFeatures))\n",
    "api.makeAvailableIn(globals())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................................................................................\n",
      ".         19s Test: paragraphs of the first verses                                           .\n",
      "..............................................................................................\n",
      "\tGenesis 1:1\n",
      "\t\t.N             1 בְּרֵאשִׁ֖ית בָּרָ֣א אֱלֹהִ֑ים אֵ֥ת הַשָּׁמַ֖יִם וְאֵ֥ת הָאָֽרֶץ׃ \n",
      "\t2\n",
      "\t\t..             1 וְהָאָ֗רֶץ הָיְתָ֥ה תֹ֨הוּ֙ וָבֹ֔הוּ \n",
      "\t\t..             1 וְחֹ֖שֶׁךְ עַל־פְּנֵ֣י תְהֹ֑ום \n",
      "\t\t..             1 וְר֣וּחַ אֱלֹהִ֔ים מְרַחֶ֖פֶת עַל־פְּנֵ֥י הַמָּֽיִם׃ \n",
      "\t3\n",
      "\t\t.#           1.1 וַיֹּ֥אמֶר אֱלֹהִ֖ים \n",
      "\t\t.q         1.1.1 יְהִ֣י אֹ֑ור \n",
      "\t\t.#         1.1.2 וַֽיְהִי־אֹֽור׃ \n",
      "\t4\n",
      "\t\t.#         1.1.3 וַיַּ֧רְא אֱלֹהִ֛ים אֶת־הָאֹ֖ור \n",
      "\t\t..         1.1.3 כִּי־טֹ֑וב \n",
      "\t\t.#         1.1.4 וַיַּבְדֵּ֣ל אֱלֹהִ֔ים בֵּ֥ין הָאֹ֖ור וּבֵ֥ין הַחֹֽשֶׁךְ׃ \n",
      "\t5\n",
      "\t\t.#         1.1.5 וַיִּקְרָ֨א אֱלֹהִ֤ים׀ לָאֹור֙ יֹ֔ום \n",
      "\t\t..         1.1.5 וְלַחֹ֖שֶׁךְ קָ֣רָא לָ֑יְלָה \n",
      "\t\t.#       1.1.5.1 וַֽיְהִי־עֶ֥רֶב \n",
      "\t\t.#       1.1.5.2 וַֽיְהִי־בֹ֖קֶר \n",
      "\t\t..       1.1.5.2 יֹ֥ום אֶחָֽד׃ פ \n",
      "\t6\n",
      "\t\t.#           1.2 וַיֹּ֣אמֶר אֱלֹהִ֔ים \n",
      "\t\t.q         1.2.1 יְהִ֥י רָקִ֖יעַ בְּתֹ֣וךְ הַמָּ֑יִם \n",
      "\t\t..         1.2.1 וִיהִ֣י מַבְדִּ֔יל בֵּ֥ין מַ֖יִם לָמָֽיִם׃ \n",
      "\t7\n",
      "\t\t.#         1.2.2 וַיַּ֣עַשׂ אֱלֹהִים֮ אֶת־הָרָקִיעַ֒ \n",
      "\t\t..         1.2.2 וַיַּבְדֵּ֗ל בֵּ֤ין הַמַּ֨יִם֙ \n",
      "\t\t.e         1.2.2 אֲשֶׁר֙ מִתַּ֣חַת לָרָקִ֔יעַ \n",
      "\t\td.         1.2.2 וּבֵ֣ין הַמַּ֔יִם \n",
      "\t\t..         1.2.2 אֲשֶׁ֖ר מֵעַ֣ל לָרָקִ֑יעַ \n",
      "\t\t..         1.2.2 וַֽיְהִי־כֵֽן׃ \n",
      "\t8\n",
      "\t\t.#       1.2.2.1 וַיִּקְרָ֧א אֱלֹהִ֛ים לָֽרָקִ֖יעַ שָׁמָ֑יִם \n",
      "\t\t.#     1.2.2.1.1 וַֽיְהִי־עֶ֥רֶב \n",
      "\t\t.#     1.2.2.1.2 וַֽיְהִי־בֹ֖קֶר \n",
      "\t\t..     1.2.2.1.2 יֹ֥ום שֵׁנִֽי׃ פ \n",
      "\t9\n",
      "\t\t.#           1.3 וַיֹּ֣אמֶר אֱלֹהִ֗ים \n",
      "\t\t.q         1.3.1 יִקָּו֨וּ הַמַּ֜יִם מִתַּ֤חַת הַשָּׁמַ֨יִם֙ אֶל־מָקֹ֣ום אֶחָ֔ד \n",
      "\t\t..         1.3.1 וְתֵרָאֶ֖ה הַיַּבָּשָׁ֑ה \n",
      "\t\t..           1.3 וַֽיְהִי־כֵֽן׃ \n",
      "\t10\n",
      "\t\t.#         1.3.2 וַיִּקְרָ֨א אֱלֹהִ֤ים׀ לַיַּבָּשָׁה֙ אֶ֔רֶץ \n",
      "\t\t..         1.3.2 וּלְמִקְוֵ֥ה הַמַּ֖יִם קָרָ֣א יַמִּ֑ים \n",
      "\t\t.#         1.3.3 וַיַּ֥רְא אֱלֹהִ֖ים \n",
      "\t\t..         1.3.3 כִּי־טֹֽוב׃ \n"
     ]
    }
   ],
   "source": [
    "utils.caption(4, 'Test: paragraphs of the first verses')\n",
    "\n",
    "def showParagraphs(verseNode):\n",
    "    clause_atoms = L.d(verseNode, otype='clause_atom')\n",
    "    for ca in clause_atoms:\n",
    "        utils.caption(0, '\\t\\t{:<3} {:>12} {}'.format(\n",
    "            F.instruction.v(ca),\n",
    "            F.pargr.v(ca),\n",
    "            T.text(L.d(ca, otype='word'))\n",
    "        ), continuation=True)\n",
    "\n",
    "for (i, verseNode) in enumerate(F.otype.s('verse')[0:10]):\n",
    "    verseLabel = T.sectionFromNode(verseNode)\n",
    "    verseHeading = '{} {}:{}'.format(*verseLabel) if i == 0 else verseLabel[2]\n",
    "    utils.caption(0, '\\t{}'.format(verseHeading), continuation=True)\n",
    "    showParagraphs(verseNode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
