{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"right\" src=\"tf-small.png\"/>\n",
    "\n",
    "![mql](emdros.png)\n",
    "\n",
    "# TF from MQL\n",
    "\n",
    "This notebook can read an\n",
    "[MQL](https://emdros.org/mql.html)\n",
    "dump of a version of the [BHSA](https://github.com/ETCBC/bhsa) Hebrew Text Database\n",
    "and transform it in a Text-Fabric\n",
    "[Text-Fabric](https://github.com/ETCBC/text-fabric)\n",
    "resource.\n",
    "\n",
    "## Discussion\n",
    "\n",
    "The principled way of going about such a conversion is to import the MQL source into\n",
    "an [Emdros](https://emdros.org) database, and use it to retrieve objects and features from there.\n",
    "\n",
    "Because the syntax of an MQL file leaves some freedom, it is error prone to do a text-to-text conversion from\n",
    "MQL to something else.\n",
    "\n",
    "Yet this is what we do, the error-prone thing. We then avoid installing and configuring and managing Emdros, MySQL/sqLite3.\n",
    "Aside the upfront work to get this going, the going after that would also be much slower.\n",
    "\n",
    "So here you are, a smallish script to do an awful lot of work, mostly correct, if careful used.\n",
    "\n",
    "# Caveat\n",
    "\n",
    "This notebook makes use of a new feature of text-fabric, first present in 2.3.12.\n",
    "Make sure to upgrade first.\n",
    "\n",
    "```sudo -H pip3 install --upgrade text-fabric\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os,sys,re,collections\n",
    "from shutil import rmtree\n",
    "from tf.fabric import Fabric\n",
    "from tf.helpers import setFromSpec\n",
    "import utils\n",
    "from blang import bookLangs, bookNames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline\n",
    "See [operation](https://github.com/ETCBC/pipeline/blob/master/README.md#operation) \n",
    "for how to run this script in the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if 'SCRIPT' not in locals():\n",
    "    SCRIPT = False\n",
    "    FORCE = True\n",
    "    CORE_NAME = 'bhsa'\n",
    "    VERSION = 'c'\n",
    "\n",
    "def stop(good=False):\n",
    "    if SCRIPT: sys.exit(0 if good else 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up the context: source file and target directories\n",
    "\n",
    "The conversion is executed in an environment of directories, so that sources, temp files and\n",
    "results are in convenient places and do not have to be shifted around."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "repoBase = os.path.expanduser('~/github/etcbc')\n",
    "thisRepo = '{}/{}'.format(repoBase, CORE_NAME)\n",
    "\n",
    "thisSource = '{}/source/{}'.format(thisRepo, VERSION)\n",
    "mqlzFile = '{}/{}.mql.bz2'.format(thisSource, CORE_NAME)\n",
    "\n",
    "thisTemp = '{}/_temp/{}'.format(thisRepo, VERSION)\n",
    "thisTempSource = '{}/source'.format(thisTemp)\n",
    "mqlFile = '{}/{}.mql'.format(thisTempSource, CORE_NAME)\n",
    "thisTempTf = '{}/tf'.format(thisTemp)\n",
    "\n",
    "thisTf = '{}/tf/{}'.format(thisRepo, VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test\n",
    "\n",
    "Check whether this conversion is needed in the first place.\n",
    "Only when run as a script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if SCRIPT:\n",
    "    testFile = '{}/.tf/otype.tfx'.format(thisTf)\n",
    "    (good, work) = utils.mustRun(mqlzFile, '{}/.tf/otype.tfx'.format(thisTf), force=FORCE)\n",
    "    if not good: stop(good=False)\n",
    "    if not work: stop(good=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF Settings\n",
    "\n",
    "We add some custom information here.\n",
    "\n",
    "* the MQL object type that corresponds to the TF slot type, typically `word`;\n",
    "* a piece of metadata that will go into every feature; the time will be added automatically\n",
    "* suitable text formats for the `otext` feature of TF.\n",
    "\n",
    "The oText feature is very sensitive to what is available in the source MQL.\n",
    "It needs to be configured here.\n",
    "We save the configs we need per source and version.\n",
    "And we define a stripped down default version to start with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "slotType = 'word'\n",
    "\n",
    "featureMetadata = dict(\n",
    "    dataset='BHSA',\n",
    "    datasetName='Biblia Hebraica Stuttgartensia Amstelodamensis',\n",
    "    author='Eep Talstra Centre for Bible and Computer',\n",
    "    encoders='Constantijn Sikkel (QDF), Ulrik Petersen (MQL) and Dirk Roorda (TF)',\n",
    "    website='https://shebanq.ancient-data.org',\n",
    "    email='shebanq@ancient-data.org',\n",
    ")\n",
    "\n",
    "oText = {\n",
    "    '': {\n",
    "        '': '''\n",
    "@sectionFeatures=book,chapter,verse\n",
    "@sectionTypes=book,chapter,verse\n",
    "@fmt:text-orig-full={g_word_utf8}{g_suffix_utf8}\n",
    "''',\n",
    "    },\n",
    "    '4': '''\n",
    "@fmt:lex-orig-full={g_lex_utf8} \n",
    "@fmt:lex-orig-plain={lex_utf8} \n",
    "@fmt:lex-trans-full={g_lex} \n",
    "@fmt:lex-trans-plain={lex} \n",
    "@fmt:text-orig-full={g_qere_utf8/g_word_utf8}{qtrailer_utf8/trailer_utf8}\n",
    "@fmt:text-orig-full-ketiv={g_word_utf8}{trailer_utf8}\n",
    "@fmt:text-orig-plain={g_cons_utf8}{trailer_utf8}\n",
    "@fmt:text-trans-full={g_word} \n",
    "@fmt:text-trans-full-ketiv={g_word} \n",
    "@fmt:text-trans-plain={g_cons} \n",
    "@sectionFeatures=book,chapter,verse\n",
    "@sectionTypes=book,chapter,verse\n",
    "''',\n",
    "    '4b': '''\n",
    "@fmt:lex-orig-full={g_lex_utf8} \n",
    "@fmt:lex-orig-plain={lex_utf8} \n",
    "@fmt:lex-trans-full={g_lex} \n",
    "@fmt:lex-trans-plain={lex} \n",
    "@fmt:text-orig-full={g_qere_utf8/g_word_utf8}{qtrailer_utf8/trailer_utf8}\n",
    "@fmt:text-orig-full-ketiv={g_word_utf8}{trailer_utf8}\n",
    "@fmt:text-orig-plain={g_cons_utf8}{trailer_utf8}\n",
    "@fmt:text-trans-full={g_word} \n",
    "@fmt:text-trans-full-ketiv={g_word} \n",
    "@fmt:text-trans-plain={g_cons} \n",
    "@sectionFeatures=book,chapter,verse\n",
    "@sectionTypes=book,chapter,verse\n",
    "''',\n",
    "    'c': '''\n",
    "@fmt:lex-orig-full={g_lex_utf8} \n",
    "@fmt:lex-orig-plain={lex_utf8} \n",
    "@fmt:lex-trans-full={g_lex} \n",
    "@fmt:lex-trans-plain={lex} \n",
    "@fmt:text-orig-full={g_word_utf8}{trailer_utf8}\n",
    "@fmt:text-orig-plain={g_cons_utf8}{trailer_utf8}\n",
    "@fmt:text-trans-full={g_word}{trailer}\n",
    "@fmt:text-trans-plain={g_cons}{trailer}\n",
    "@sectionFeatures=book,chapter,verse\n",
    "@sectionTypes=book,chapter,verse\n",
    "''',\n",
    "    '2016': '''\n",
    "@fmt:lex-orig-full={g_lex_utf8} \n",
    "@fmt:lex-orig-plain={lex_utf8} \n",
    "@fmt:lex-trans-full={g_lex} \n",
    "@fmt:lex-trans-plain={lex} \n",
    "@fmt:text-orig-full={g_word_utf8}{trailer_utf8}\n",
    "@fmt:text-orig-plain={g_cons_utf8}{trailer_utf8}\n",
    "@fmt:text-trans-full={g_word}{trailer}\n",
    "@fmt:text-trans-plain={g_cons}{trailer}\n",
    "@sectionFeatures=book,chapter,verse\n",
    "@sectionTypes=book,chapter,verse\n",
    "''',\n",
    "    '2017': '''\n",
    "@fmt:lex-orig-full={g_lex_utf8} \n",
    "@fmt:lex-orig-plain={lex_utf8} \n",
    "@fmt:lex-trans-full={g_lex} \n",
    "@fmt:lex-trans-plain={lex} \n",
    "@fmt:text-orig-full={g_word_utf8}{trailer_utf8}\n",
    "@fmt:text-orig-plain={g_cons_utf8}{trailer_utf8}\n",
    "@fmt:text-trans-full={g_word}{trailer}\n",
    "@fmt:text-trans-plain={g_cons}{trailer}\n",
    "@sectionFeatures=book,chapter,verse\n",
    "@sectionTypes=book,chapter,verse\n",
    "''',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next function selects the proper otext material, falling back on a default if nothing \n",
    "appropriate has been specified in `oText`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def getOtext():\n",
    "    thisOtext = oText.get(VERSION, oText[''])\n",
    "    otextInfo = dict(line[1:].split('=', 1) for line in thisOtext.strip('\\n').split('\\n'))\n",
    "\n",
    "    if thisOtext is oText['']:\n",
    "        utils.caption(0, 'WARNING: no otext feature info provided, using a meager default value') \n",
    "    else:\n",
    "        utils.caption(0, 'INFO: otext feature information found')\n",
    "    for x in sorted(otextInfo.items()):\n",
    "        utils.caption(0, '\\t{:<20} = \"{}\"'.format(*x))\n",
    "    return otextInfo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "The program has several stages:\n",
    "   \n",
    "1. **prepare** the source (utils.bunzip if needed)\n",
    "1. **parse MQL** and collect information in datastructures\n",
    "1. **transform to TF** write the datastructures as TF features\n",
    "1. **differences** (informational)\n",
    "1. **deliver** the tf data at its destination directory\n",
    "1. **compile** all tf features to binary format\n",
    "\n",
    "Stages **parseMQL** and **transform to TF** communicate with the help of several global variables:\n",
    "\n",
    "* data containers for the MQL kinds of data\n",
    "  * enumerations\n",
    "  * object types\n",
    "  * tables\n",
    "\n",
    "* data containers for the TF features to be generated,\n",
    "  * node features\n",
    "  * edge features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "objectTypes = dict()\n",
    "tables = dict()\n",
    "\n",
    "edgeF = dict()\n",
    "nodeF = dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage: Prepare\n",
    "\n",
    "Check the source, utils.bunzip it if needed, empty the result directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def prepare():\n",
    "    global thisoText\n",
    "\n",
    "    if not os.path.exists(thisTempSource):\n",
    "        os.makedirs(thisTempSource)\n",
    "\n",
    "    utils.caption(0, 'bunzipping {} ...'.format(mqlzFile))\n",
    "    utils.bunzip(mqlzFile, mqlFile)\n",
    "    utils.caption(0, 'Done')\n",
    "\n",
    "    if os.path.exists(thisTempTf): rmtree(thisTempTf)\n",
    "    os.makedirs(thisTempTf)\n",
    "\n",
    "    thisoText = getOtext()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert a monads specification (a comma separated sequence of numbers and number ranges)\n",
    "into a set of integers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage: MQL parsing\n",
    "Plough through the MQL file and grab all relevant information\n",
    "and put it into the dedicated data structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "uniscan = re.compile(r'(?:\\\\x..)+')\n",
    "\n",
    "def makeuni(match):\n",
    "    ''' Make proper unicode of a text that contains byte escape codes such as backslash xb6\n",
    "    '''\n",
    "    byts = eval('\"' + match.group(0) + '\"')\n",
    "    return byts.encode('latin1').decode('utf-8')\n",
    "\n",
    "def uni(line): return uniscan.sub(makeuni, line)\n",
    "    \n",
    "def parseMql():\n",
    "    utils.caption(4, 'Parsing mql source ...')\n",
    "    fh = open(mqlFile)\n",
    "\n",
    "    curId = None\n",
    "    curEnum = None\n",
    "    curObjectType = None\n",
    "    curTable = None\n",
    "    curObject = None\n",
    "    curValue = None\n",
    "    curFeature = None\n",
    "\n",
    "    STRING_TYPES = {'ascii', 'string'}\n",
    "\n",
    "    enums = dict()\n",
    "\n",
    "    chunkSize = 1000000\n",
    "    inThisChunk = 0\n",
    "\n",
    "    good = True\n",
    "\n",
    "    for (ln, line) in enumerate(fh):\n",
    "        inThisChunk += 1\n",
    "        if inThisChunk == chunkSize:\n",
    "            utils.caption(0, '\\tline {:>9}'.format(ln + 1))\n",
    "            inThisChunk = 0\n",
    "        if line.startswith('CREATE OBJECTS WITH OBJECT TYPE') or line.startswith('WITH OBJECT TYPE'):\n",
    "            comps = line.rstrip().rstrip(']').split('[', 1)\n",
    "            curTable = comps[1]\n",
    "            utils.caption(0, '\\t\\tobjects in {}'.format(curTable))\n",
    "            curObject = None\n",
    "            if not curTable in tables:\n",
    "                tables[curTable] = dict()\n",
    "        elif curEnum != None:\n",
    "            if line.startswith('}'):\n",
    "                curEnum = None\n",
    "                continue\n",
    "            comps = line.strip().rstrip(',').split('=', 1)\n",
    "            comp = comps[0].strip()\n",
    "            words = comp.split()\n",
    "            if words[0] == 'DEFAULT':\n",
    "                enums[curEnum]['default'] = uni(words[1])\n",
    "                value = words[1]\n",
    "            else:\n",
    "                value = words[0]\n",
    "            enums[curEnum]['values'].append(value)\n",
    "        elif curObjectType != None:\n",
    "            if line.startswith(']'):\n",
    "                curObjectType = None\n",
    "                continue\n",
    "            if curObjectType == True:\n",
    "                if line.startswith('['):\n",
    "                    curObjectType = line.rstrip()[1:]\n",
    "                    objectTypes[curObjectType] = dict()\n",
    "                    utils.caption(0, '\\t\\totype {}'.format(curObjectType))\n",
    "                    continue\n",
    "            comps = line.strip().rstrip(';').split(':', 1)\n",
    "            feature = comps[0].strip()\n",
    "            fInfo = comps[1].strip()\n",
    "            fCleanInfo = fInfo.replace('FROM SET', '')\n",
    "            fInfoComps = fCleanInfo.split(' ', 1)\n",
    "            fMQLType = fInfoComps[0]\n",
    "            fDefault = fInfoComps[1].strip().split(' ', 1)[1] if len(fInfoComps) == 2 else None\n",
    "            if fDefault != None and fMQLType in STRING_TYPES:\n",
    "                fDefault = uni(fDefault[1:-1])\n",
    "            default = enums.get(fMQLType, {}).get('default', fDefault)\n",
    "            ftype = 'str' if fMQLType in enums else\\\n",
    "                    'int' if fMQLType == 'integer' else\\\n",
    "                    'str' if fMQLType in STRING_TYPES else\\\n",
    "                    'int' if fInfo == 'id_d' else\\\n",
    "                    'str'\n",
    "            isEdge = fMQLType == 'id_d'\n",
    "            if isEdge:\n",
    "                edgeF.setdefault(curObjectType, set()).add(feature)\n",
    "            else:\n",
    "                nodeF.setdefault(curObjectType, set()).add(feature)\n",
    "\n",
    "            objectTypes[curObjectType][feature] = (ftype, default)\n",
    "            utils.caption(0, '\\t\\t\\tfeature {} ({}) =def= {} : {}'.format(feature, ftype, default, 'edge' if isEdge else 'node'))\n",
    "        elif curTable != None:\n",
    "            if curObject != None:\n",
    "                if line.startswith(']'):\n",
    "                    objectType = objectTypes[curTable]\n",
    "                    for (feature, (ftype, default)) in objectType.items():\n",
    "                        if feature not in curObject['feats'] and default != None:\n",
    "                            curObject['feats'][feature] = default\n",
    "                    tables[curTable][curId] = curObject\n",
    "                    curObject = None\n",
    "                    continue\n",
    "                elif line.startswith('['):\n",
    "                    continue\n",
    "                elif line.startswith('FROM MONADS'):\n",
    "                    monads = line.split('=', 1)[1].replace('{', '').replace('}', '').replace(' ','').strip()\n",
    "                    curObject['monads'] = setFromSpec(monads)\n",
    "                elif line.startswith('WITH ID_D'):\n",
    "                    comps = line.replace('[', '').rstrip().split('=', 1)\n",
    "                    curId = int(comps[1])\n",
    "                elif line.startswith('GO'):\n",
    "                    continue\n",
    "                elif line.strip() == '':\n",
    "                    continue\n",
    "                else:\n",
    "                    if curValue != None:\n",
    "                        toBeContinued = not line.rstrip().endswith('\";')\n",
    "                        if toBeContinued:\n",
    "                            curValue += line\n",
    "                        else:\n",
    "                            curValue += line.rstrip().rstrip(';').rstrip('\"')\n",
    "                            curObject['feats'][curFeature] = uni(curValue)\n",
    "                            curValue = None\n",
    "                            curFeature = None\n",
    "                        continue\n",
    "                    if ':=' in line:\n",
    "                        (featurePart, valuePart) = line.split('=', 1)\n",
    "                        feature = featurePart[0:-1].strip()\n",
    "                        isText = ':=\"' in line\n",
    "                        toBeContinued = isText and not line.rstrip().endswith('\";')\n",
    "                        if toBeContinued:\n",
    "                            # this happens if a feature value contains a new line\n",
    "                            # we must continue scanning lines until we meet the ned of the value\n",
    "                            curFeature = feature\n",
    "                            curValue = valuePart.lstrip('\"')\n",
    "                        else:\n",
    "                            value = valuePart.rstrip().rstrip(';').strip('\"')\n",
    "                            curObject['feats'][feature] = uni(value) if isText else value\n",
    "                    else:\n",
    "                        utils.caption(0, 'ERROR: line {}: unrecognized line -->{}<--'.format(ln, line))\n",
    "                        good = False\n",
    "                        break\n",
    "            else:\n",
    "                if line.startswith('CREATE OBJECT'):\n",
    "                    curObject = dict(feats=dict(), monads=None)\n",
    "                    curId = None\n",
    "        else:\n",
    "            if line.startswith('CREATE ENUMERATION'):\n",
    "                words = line.split()\n",
    "                curEnum = words[2]\n",
    "                enums[curEnum] = dict(default=None, values=[])\n",
    "                utils.caption(0, '\\t\\tenum {}'.format(curEnum))\n",
    "            elif line.startswith('CREATE OBJECT TYPE'):\n",
    "                curObjectType = True\n",
    "    utils.caption(0, '{} lines parsed'.format(ln + 1))\n",
    "    fh.close()\n",
    "    for table in tables:\n",
    "        utils.caption(0, '{} objects of type {}'.format(len(tables[table]), table))\n",
    "    if not good:\n",
    "        stop(good=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage: TF generation\n",
    "Transform the collected information in feature-like datastructures, and write it all\n",
    "out to `.tf` files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def tfFromData():\n",
    "    utils.caption(4, 'Making TF data ...')\n",
    "    \n",
    "    NIL = {'nil', 'NIL', 'Nil'}\n",
    "\n",
    "    tableOrder = [slotType]+[t for t in sorted(tables) if t != slotType]\n",
    "\n",
    "    nodeFromIdd = dict()\n",
    "    iddFromNode = dict()\n",
    "\n",
    "    nodeFeatures = dict()\n",
    "    edgeFeatures = dict()\n",
    "    metaData = dict()\n",
    "\n",
    "    # metadata that ends up in every feature\n",
    "    metaData[''] = featureMetadata\n",
    "\n",
    "    # the config feature otext\n",
    "    metaData['otext'] = thisoText\n",
    "\n",
    "    # multilingual book names\n",
    "    for (langCode, (langEnglish, langName)) in bookLangs.items():\n",
    "        metaData['book@{}'.format(langCode)] = {\n",
    "            'valueType': 'str',\n",
    "            'language': langName,\n",
    "            'languageCode': langCode,\n",
    "            'languageEnglish': langEnglish,\n",
    "        }\n",
    "\n",
    "    utils.caption(0, 'Monad - idd mapping ...')\n",
    "    otype = dict()\n",
    "    for idd in tables.get(slotType, {}):\n",
    "        monad = list(tables[slotType][idd]['monads'])[0]\n",
    "        nodeFromIdd[idd] = monad\n",
    "        iddFromNode[monad] = idd\n",
    "        otype[monad] = slotType\n",
    "\n",
    "    maxSlot = max(nodeFromIdd.values()) if len(nodeFromIdd) else 0\n",
    "    utils.caption(0, 'maxSlot={}'.format(maxSlot))\n",
    "\n",
    "    utils.caption(0, 'Node mapping and otype ...')\n",
    "    node = maxSlot\n",
    "    for t in tableOrder[1:]:\n",
    "        for idd in sorted(tables[t]):\n",
    "            node += 1\n",
    "            nodeFromIdd[idd] = node\n",
    "            iddFromNode[node] = idd\n",
    "            otype[node] = t\n",
    "\n",
    "    nodeFeatures['otype'] = otype\n",
    "    metaData['otype'] = dict(\n",
    "        valueType='str',\n",
    "    )\n",
    "\n",
    "    utils.caption(0, 'oslots ...')\n",
    "    oslots = dict()\n",
    "    for t in tableOrder[1:]:\n",
    "        for idd in tables.get(t, {}):\n",
    "            node = nodeFromIdd[idd]\n",
    "            monads = tables[t][idd]['monads']\n",
    "            oslots[node] = monads\n",
    "    edgeFeatures['oslots'] = oslots\n",
    "    metaData['oslots'] = dict(\n",
    "        valueType='str',\n",
    "    )\n",
    "\n",
    "    utils.caption(0, 'metadata ...')\n",
    "    for t in nodeF:\n",
    "        for f in nodeF[t]:\n",
    "            ftype = objectTypes[t][f][0]\n",
    "            metaData.setdefault(f, {})['valueType'] = ftype\n",
    "    for t in edgeF:\n",
    "        for f in edgeF[t]:\n",
    "            metaData.setdefault(f, {})['valueType'] = 'str'\n",
    "\n",
    "    utils.caption(4, 'features ...')\n",
    "    chunkSize = 100000\n",
    "    for t in tableOrder:\n",
    "        utils.caption(0, '\\tfeatures from {}s'.format(t))\n",
    "        inThisChunk = 0\n",
    "        for (i, idd) in enumerate(tables.get(t, {})):\n",
    "            inThisChunk += 1\n",
    "            if inThisChunk == chunkSize:\n",
    "                utils.caption(0, '\\t{:>9} {}s'.format(i + 1, t))\n",
    "                inThisChunk = 0\n",
    "            node = nodeFromIdd[idd]\n",
    "            features = tables[t][idd]['feats']\n",
    "            for (f, v) in features.items():\n",
    "                isEdge = f in edgeF.get(t, set())\n",
    "                if isEdge:\n",
    "                    if v not in NIL:\n",
    "                        edgeFeatures.setdefault(f, {}).setdefault(node, set()).add(nodeFromIdd[int(v)])\n",
    "                else:\n",
    "                    nodeFeatures.setdefault(f, {})[node] = v\n",
    "        utils.caption(0, '\\t{:>9} {}s'.format(i + 1, t))\n",
    "\n",
    "    utils.caption(0, 'book names ...')\n",
    "    nodeFeatures['book@la'] = nodeFeatures.get('book', {})\n",
    "    bookNodes = sorted(nodeFeatures.get('book', {}))\n",
    "    for (langCode, langBookNames) in bookNames.items():\n",
    "        nodeFeatures['book@{}'.format(langCode)] = dict(zip(bookNodes, langBookNames))\n",
    "\n",
    "    utils.caption(4, 'write data set to TF ...')\n",
    "\n",
    "    TF = Fabric(locations=thisTempTf, silent=True)\n",
    "    TF.save(nodeFeatures=nodeFeatures, edgeFeatures=edgeFeatures, metaData=metaData)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage: Diffs\n",
    "\n",
    "Check differences with previous versions.\n",
    "\n",
    "The new dataset has been created in a temporary directory,\n",
    "and has not yet been copied to its destination.\n",
    "\n",
    "Here is your opportunity to compare the newly created features with the older features.\n",
    "You expect some differences in some features.\n",
    "\n",
    "We check the differences between the previous version of the features and what has been generated.\n",
    "We list features that will be added and deleted and changed.\n",
    "For each changed feature we show the first line where the new feature differs from the old one.\n",
    "We ignore changes in the metadata, because the timestamp in the metadata will always change."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage: Deliver \n",
    "\n",
    "Copy the new TF dataset from the temporary location where it has been created to its final destination."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage: Compile TF\n",
    "\n",
    "Just to see whether everything loads and the precomputing of extra information works out.\n",
    "Moreover, if you want to work with these features, then the precomputing has already been done, and everything is quicker in subsequent runs.\n",
    "\n",
    "We issue load statement to trigger the precomputing of extra data.\n",
    "Note that all features specified text formats in the `otext` config feature,\n",
    "will be loaded, as well as the features for sections.\n",
    "\n",
    "At that point we have access to the full list of features.\n",
    "We grab them and are going to load them all! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def compileTfData():\n",
    "    utils.caption(4, 'Load and compile standard TF features')\n",
    "    TF = Fabric(locations=thisTf, modules=[''])\n",
    "    api = TF.load('')\n",
    "\n",
    "    utils.caption(4, 'Load and compile all other TF features')\n",
    "    allFeatures = TF.explore(silent=False, show=True)\n",
    "    loadableFeatures = allFeatures['nodes'] + allFeatures['edges']\n",
    "    api = TF.load(loadableFeatures)\n",
    "    T = api.T\n",
    "    \n",
    "    utils.caption(4, 'Basic test')\n",
    "    utils.caption(4, 'First verse in all formats')\n",
    "    for fmt in T.formats:\n",
    "        utils.caption(0, '{}'.format(fmt), continuation=True)\n",
    "        utils.caption(0, '\\t{}'.format(T.text(range(1,12), fmt=fmt)), continuation=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|      1m 10s bunzipping /Users/dirk/github/etcbc/bhsa/source/c/bhsa.mql.bz2 ...\n",
      "|      1m 10s \tNOTE: Using existing unzipped file which is newer than bzipped one\n",
      "|      1m 10s Done\n",
      "|      1m 10s INFO: otext feature information found\n",
      "|      1m 10s \tfmt:lex-orig-full    = \"{g_lex_utf8} \"\n",
      "|      1m 10s \tfmt:lex-orig-plain   = \"{lex_utf8} \"\n",
      "|      1m 10s \tfmt:lex-trans-full   = \"{g_lex} \"\n",
      "|      1m 10s \tfmt:lex-trans-plain  = \"{lex} \"\n",
      "|      1m 10s \tfmt:text-orig-full   = \"{g_word_utf8}{trailer_utf8}\"\n",
      "|      1m 10s \tfmt:text-orig-plain  = \"{g_cons_utf8}{trailer_utf8}\"\n",
      "|      1m 10s \tfmt:text-trans-full  = \"{g_word}{trailer}\"\n",
      "|      1m 10s \tfmt:text-trans-plain = \"{g_cons}{trailer}\"\n",
      "|      1m 10s \tsectionFeatures      = \"book,chapter,verse\"\n",
      "|      1m 10s \tsectionTypes         = \"book,chapter,verse\"\n"
     ]
    }
   ],
   "source": [
    "prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................................................................................\n",
      ".      1m 22s Parsing mql source ...                                                         .\n",
      "..............................................................................................\n",
      "|      1m 22s \t\tenum boolean_t\n",
      "|      1m 22s \t\tenum phrase_determination_t\n",
      "|      1m 22s \t\tenum language_t\n",
      "|      1m 22s \t\tenum book_name_t\n",
      "|      1m 22s \t\tenum lexical_set_t\n",
      "|      1m 22s \t\tenum verbal_stem_t\n",
      "|      1m 22s \t\tenum verbal_tense_t\n",
      "|      1m 22s \t\tenum person_t\n",
      "|      1m 22s \t\tenum number_t\n",
      "|      1m 22s \t\tenum gender_t\n",
      "|      1m 22s \t\tenum state_t\n",
      "|      1m 22s \t\tenum part_of_speech_t\n",
      "|      1m 22s \t\tenum phrase_type_t\n",
      "|      1m 22s \t\tenum phrase_atom_relation_t\n",
      "|      1m 22s \t\tenum phrase_relation_t\n",
      "|      1m 22s \t\tenum phrase_atom_unit_distance_to_mother_t\n",
      "|      1m 22s \t\tenum subphrase_relation_t\n",
      "|      1m 22s \t\tenum subphrase_mother_object_type_t\n",
      "|      1m 22s \t\tenum phrase_function_t\n",
      "|      1m 22s \t\tenum clause_atom_type_t\n",
      "|      1m 22s \t\tenum clause_type_t\n",
      "|      1m 22s \t\tenum clause_kind_t\n",
      "|      1m 22s \t\tenum clause_constituent_relation_t\n",
      "|      1m 22s \t\tenum clause_constituent_mother_object_type_t\n",
      "|      1m 22s \t\tenum clause_constituent_unit_distance_to_mother_t\n",
      "|      1m 22s \t\totype word\n",
      "|      1m 22s \t\t\tfeature number (int) =def= 0 : node\n",
      "|      1m 22s \t\t\tfeature g_voc_lex (str) =def=  : node\n",
      "|      1m 22s \t\t\tfeature g_vbe_utf8 (str) =def=  : node\n",
      "|      1m 22s \t\t\tfeature g_voc_lex_utf8 (str) =def=  : node\n",
      "|      1m 22s \t\t\tfeature g_nme (str) =def=  : node\n",
      "|      1m 22s \t\t\tfeature nme (str) =def=  : node\n",
      "|      1m 22s \t\t\tfeature g_vbe (str) =def=  : node\n",
      "|      1m 22s \t\t\tfeature g_word (str) =def=  : node\n",
      "|      1m 22s \t\t\tfeature g_cons_utf8 (str) =def=  : node\n",
      "|      1m 22s \t\t\tfeature g_cons (str) =def=  : node\n",
      "|      1m 22s \t\t\tfeature g_word_utf8 (str) =def=  : node\n",
      "|      1m 22s \t\t\tfeature trailer (str) =def=  : node\n",
      "|      1m 22s \t\t\tfeature trailer_utf8 (str) =def=  : node\n",
      "|      1m 22s \t\t\tfeature g_pfm (str) =def=  : node\n",
      "|      1m 22s \t\t\tfeature g_pfm_utf8 (str) =def=  : node\n",
      "|      1m 22s \t\t\tfeature g_vbs (str) =def=  : node\n",
      "|      1m 22s \t\t\tfeature g_vbs_utf8 (str) =def=  : node\n",
      "|      1m 22s \t\t\tfeature lex (str) =def=  : node\n",
      "|      1m 22s \t\t\tfeature lex_utf8 (str) =def=  : node\n",
      "|      1m 22s \t\t\tfeature g_lex (str) =def=  : node\n",
      "|      1m 22s \t\t\tfeature g_lex_utf8 (str) =def=  : node\n",
      "|      1m 22s \t\t\tfeature g_prs_utf8 (str) =def=  : node\n",
      "|      1m 22s \t\t\tfeature g_prs (str) =def=  : node\n",
      "|      1m 22s \t\t\tfeature qere_utf8 (str) =def=  : node\n",
      "|      1m 22s \t\t\tfeature g_uvf_utf8 (str) =def=  : node\n",
      "|      1m 22s \t\t\tfeature g_uvf (str) =def=  : node\n",
      "|      1m 22s \t\t\tfeature qere (str) =def=  : node\n",
      "|      1m 22s \t\t\tfeature g_nme_utf8 (str) =def=  : node\n",
      "|      1m 22s \t\t\tfeature functional_parent (str) =def= 0 : edge\n",
      "|      1m 22s \t\t\tfeature distributional_parent (str) =def= 0 : edge\n",
      "|      1m 22s \t\t\tfeature pfm (str) =def=  : node\n",
      "|      1m 22s \t\t\tfeature prs (str) =def=  : node\n",
      "|      1m 22s \t\t\tfeature uvf (str) =def=  : node\n",
      "|      1m 22s \t\t\tfeature vbe (str) =def=  : node\n",
      "|      1m 22s \t\t\tfeature vbs (str) =def=  : node\n",
      "|      1m 22s \t\t\tfeature language (str) =def= Hebrew : node\n",
      "|      1m 22s \t\t\tfeature ls (str) =def= none : node\n",
      "|      1m 22s \t\t\tfeature vs (str) =def= NA : node\n",
      "|      1m 22s \t\t\tfeature vt (str) =def= NA : node\n",
      "|      1m 22s \t\t\tfeature prs_ps (str) =def= NA : node\n",
      "|      1m 22s \t\t\tfeature ps (str) =def= NA : node\n",
      "|      1m 22s \t\t\tfeature nu (str) =def= NA : node\n",
      "|      1m 22s \t\t\tfeature prs_nu (str) =def= NA : node\n",
      "|      1m 22s \t\t\tfeature prs_gn (str) =def= NA : node\n",
      "|      1m 22s \t\t\tfeature gn (str) =def= NA : node\n",
      "|      1m 22s \t\t\tfeature st (str) =def= NA : node\n",
      "|      1m 22s \t\t\tfeature sp (str) =def= art : node\n",
      "|      1m 22s \t\t\tfeature pdp (str) =def= art : node\n",
      "|      1m 22s \t\totype clause_atom\n",
      "|      1m 22s \t\t\tfeature tab (int) =def= 0 : node\n",
      "|      1m 22s \t\t\tfeature code (int) =def= 0 : node\n",
      "|      1m 22s \t\t\tfeature dist (int) =def= 0 : node\n",
      "|      1m 22s \t\t\tfeature number (int) =def= 0 : node\n",
      "|      1m 22s \t\t\tfeature distributional_parent (str) =def= 0 : edge\n",
      "|      1m 22s \t\t\tfeature mother (str) =def= 0 : edge\n",
      "|      1m 22s \t\t\tfeature functional_parent (str) =def= 0 : edge\n",
      "|      1m 22s \t\t\tfeature is_root (str) =def= false : node\n",
      "|      1m 22s \t\t\tfeature typ (str) =def= Unkn : node\n",
      "|      1m 22s \t\totype sentence\n",
      "|      1m 22s \t\t\tfeature number (int) =def= 0 : node\n",
      "|      1m 22s \t\totype sentence_atom\n",
      "|      1m 22s \t\t\tfeature number (int) =def= 0 : node\n",
      "|      1m 22s \t\t\tfeature functional_parent (str) =def= 0 : edge\n",
      "|      1m 22s \t\totype subphrase\n",
      "|      1m 22s \t\t\tfeature mother (str) =def= 0 : edge\n",
      "|      1m 22s \t\t\tfeature rela (str) =def= NA : node\n",
      "|      1m 22s \t\t\tfeature mother_object_type (str) =def= NA : node\n",
      "|      1m 22s \t\totype phrase\n",
      "|      1m 22s \t\t\tfeature dist (int) =def= 0 : node\n",
      "|      1m 22s \t\t\tfeature number (int) =def= 0 : node\n",
      "|      1m 22s \t\t\tfeature functional_parent (str) =def= 0 : edge\n",
      "|      1m 22s \t\t\tfeature mother (str) =def= 0 : edge\n",
      "|      1m 23s \t\t\tfeature det (str) =def= NA : node\n",
      "|      1m 23s \t\t\tfeature typ (str) =def= VP : node\n",
      "|      1m 23s \t\t\tfeature rela (str) =def= NA : node\n",
      "|      1m 23s \t\t\tfeature dist_unit (str) =def= clause_atoms : node\n",
      "|      1m 23s \t\t\tfeature function (str) =def= Unkn : node\n",
      "|      1m 23s \t\totype chapter\n",
      "|      1m 23s \t\t\tfeature chapter (int) =def= 0 : node\n",
      "|      1m 23s \t\t\tfeature book (str) =def= Genesis : node\n",
      "|      1m 23s \t\totype book\n",
      "|      1m 23s \t\t\tfeature book (str) =def= Genesis : node\n",
      "|      1m 23s \t\totype clause\n",
      "|      1m 23s \t\t\tfeature dist (int) =def= 0 : node\n",
      "|      1m 23s \t\t\tfeature number (int) =def= 0 : node\n",
      "|      1m 23s \t\t\tfeature domain (str) =def=  : node\n",
      "|      1m 23s \t\t\tfeature mother (str) =def= 0 : edge\n",
      "|      1m 23s \t\t\tfeature functional_parent (str) =def= 0 : edge\n",
      "|      1m 23s \t\t\tfeature txt (str) =def=  : node\n",
      "|      1m 23s \t\t\tfeature typ (str) =def= Unkn : node\n",
      "|      1m 23s \t\t\tfeature kind (str) =def= unknown : node\n",
      "|      1m 23s \t\t\tfeature rela (str) =def= NA : node\n",
      "|      1m 23s \t\t\tfeature mother_object_type (str) =def= clause : node\n",
      "|      1m 23s \t\t\tfeature dist_unit (str) =def= clause_atoms : node\n",
      "|      1m 23s \t\totype half_verse\n",
      "|      1m 23s \t\t\tfeature label (str) =def=  : node\n",
      "|      1m 23s \t\totype verse\n",
      "|      1m 23s \t\t\tfeature verse (int) =def= 0 : node\n",
      "|      1m 23s \t\t\tfeature chapter (int) =def= 0 : node\n",
      "|      1m 23s \t\t\tfeature label (str) =def=  : node\n",
      "|      1m 23s \t\t\tfeature book (str) =def= Genesis : node\n",
      "|      1m 23s \t\totype phrase_atom\n",
      "|      1m 23s \t\t\tfeature number (int) =def= 0 : node\n",
      "|      1m 23s \t\t\tfeature dist (int) =def= 0 : node\n",
      "|      1m 23s \t\t\tfeature distributional_parent (str) =def= 0 : edge\n",
      "|      1m 23s \t\t\tfeature mother (str) =def= 0 : edge\n",
      "|      1m 23s \t\t\tfeature functional_parent (str) =def= 0 : edge\n",
      "|      1m 23s \t\t\tfeature det (str) =def= NA : node\n",
      "|      1m 23s \t\t\tfeature typ (str) =def= VP : node\n",
      "|      1m 23s \t\t\tfeature rela (str) =def= NA : node\n",
      "|      1m 23s \t\t\tfeature dist_unit (str) =def= clause_atoms : node\n",
      "|      1m 23s \t\tobjects in word\n",
      "|      1m 30s \tline   1000000\n",
      "|      1m 36s \tline   2000000\n",
      "|      1m 40s \t\tobjects in word\n",
      "|      1m 42s \tline   3000000\n",
      "|      1m 48s \tline   4000000\n",
      "|      1m 54s \tline   5000000\n",
      "|      1m 56s \t\tobjects in word\n",
      "|      2m 00s \tline   6000000\n",
      "|      2m 06s \tline   7000000\n",
      "|      2m 11s \t\tobjects in word\n",
      "|      2m 12s \tline   8000000\n",
      "|      2m 19s \tline   9000000\n",
      "|      2m 27s \tline  10000000\n",
      "|      2m 31s \t\tobjects in word\n",
      "|      2m 37s \tline  11000000\n",
      "|      2m 45s \tline  12000000\n",
      "|      2m 51s \tline  13000000\n",
      "|      2m 51s \t\tobjects in word\n",
      "|      2m 56s \tline  14000000\n",
      "|      3m 02s \tline  15000000\n",
      "|      3m 05s \t\tobjects in word\n",
      "|      3m 07s \tline  16000000\n",
      "|      3m 13s \tline  17000000\n",
      "|      3m 19s \tline  18000000\n",
      "|      3m 20s \t\tobjects in word\n",
      "|      3m 24s \tline  19000000\n",
      "|      3m 30s \tline  20000000\n",
      "|      3m 34s \t\tobjects in word\n",
      "|      3m 35s \tline  21000000\n",
      "|      3m 41s \tline  22000000\n",
      "|      3m 42s \t\tobjects in clause_atom\n",
      "|      3m 44s \t\tobjects in clause_atom\n",
      "|      3m 45s \tline  23000000\n",
      "|      3m 46s \t\tobjects in sentence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|      3m 47s \t\tobjects in sentence\n",
      "|      3m 47s \t\tobjects in sentence_atom\n",
      "|      3m 48s \t\tobjects in sentence_atom\n",
      "|      3m 49s \tline  24000000\n",
      "|      3m 49s \t\tobjects in subphrase\n",
      "|      3m 50s \t\tobjects in subphrase\n",
      "|      3m 52s \t\tobjects in subphrase\n",
      "|      3m 52s \t\tobjects in phrase\n",
      "|      3m 53s \tline  25000000\n",
      "|      3m 54s \t\tobjects in phrase\n",
      "|      3m 56s \tline  26000000\n",
      "|      3m 57s \t\tobjects in phrase\n",
      "|      3m 59s \t\tobjects in phrase\n",
      "|      4m 00s \tline  27000000\n",
      "|      4m 01s \t\tobjects in phrase\n",
      "|      4m 03s \tline  28000000\n",
      "|      4m 03s \t\tobjects in phrase\n",
      "|      4m 04s \t\tobjects in chapter\n",
      "|      4m 04s \t\tobjects in book\n",
      "|      4m 04s \t\tobjects in clause\n",
      "|      4m 07s \t\tobjects in clause\n",
      "|      4m 07s \tline  29000000\n",
      "|      4m 09s \t\tobjects in half_verse\n",
      "|      4m 10s \t\tobjects in verse\n",
      "|      4m 11s \t\tobjects in phrase_atom\n",
      "|      4m 11s \tline  30000000\n",
      "|      4m 13s \t\tobjects in phrase_atom\n",
      "|      4m 14s \tline  31000000\n",
      "|      4m 15s \t\tobjects in phrase_atom\n",
      "|      4m 18s \t\tobjects in phrase_atom\n",
      "|      4m 19s \tline  32000000\n",
      "|      4m 20s \t\tobjects in phrase_atom\n",
      "|      4m 22s \tline  33000000\n",
      "|      4m 22s \t\tobjects in phrase_atom\n",
      "|      4m 23s 33367199 lines parsed\n",
      "|      4m 23s 426581 objects of type word\n",
      "|      4m 23s 90562 objects of type clause_atom\n",
      "|      4m 23s 63570 objects of type sentence\n",
      "|      4m 23s 64339 objects of type sentence_atom\n",
      "|      4m 23s 113792 objects of type subphrase\n",
      "|      4m 23s 253174 objects of type phrase\n",
      "|      4m 23s 929 objects of type chapter\n",
      "|      4m 23s 39 objects of type book\n",
      "|      4m 23s 88000 objects of type clause\n",
      "|      4m 23s 45180 objects of type half_verse\n",
      "|      4m 23s 23213 objects of type verse\n",
      "|      4m 23s 267515 objects of type phrase_atom\n"
     ]
    }
   ],
   "source": [
    "parseMql()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................................................................................\n",
      ".      9m 54s Making TF data ...                                                             .\n",
      "..............................................................................................\n",
      "|      9m 54s Monad - idd mapping ...\n",
      "|      9m 54s maxSlot=426581\n",
      "|      9m 54s Node mapping and otype ...\n",
      "|      9m 55s oslots ...\n",
      "|      9m 55s metadata ...\n",
      "..............................................................................................\n",
      ".      9m 55s features ...                                                                   .\n",
      "..............................................................................................\n",
      "|      9m 55s \tfeatures from words\n",
      "|      9m 59s \t   100000 words\n",
      "|     10m 03s \t   200000 words\n",
      "|     10m 07s \t   300000 words\n",
      "|     10m 10s \t   400000 words\n",
      "|     10m 11s \t   426581 words\n",
      "|     10m 11s \tfeatures from books\n",
      "|     10m 11s \t       39 books\n",
      "|     10m 11s \tfeatures from chapters\n",
      "|     10m 11s \t      929 chapters\n",
      "|     10m 11s \tfeatures from clauses\n",
      "|     10m 12s \t    88000 clauses\n",
      "|     10m 12s \tfeatures from clause_atoms\n",
      "|     10m 14s \t    90562 clause_atoms\n",
      "|     10m 14s \tfeatures from half_verses\n",
      "|     10m 14s \t    45180 half_verses\n",
      "|     10m 14s \tfeatures from phrases\n",
      "|     10m 15s \t   100000 phrases\n",
      "|     10m 16s \t   200000 phrases\n",
      "|     10m 16s \t   253174 phrases\n",
      "|     10m 16s \tfeatures from phrase_atoms\n",
      "|     10m 17s \t   100000 phrase_atoms\n",
      "|     10m 18s \t   200000 phrase_atoms\n",
      "|     10m 19s \t   267515 phrase_atoms\n",
      "|     10m 19s \tfeatures from sentences\n",
      "|     10m 19s \t    63570 sentences\n",
      "|     10m 19s \tfeatures from sentence_atoms\n",
      "|     10m 19s \t    64339 sentence_atoms\n",
      "|     10m 19s \tfeatures from subphrases\n",
      "|     10m 19s \t   100000 subphrases\n",
      "|     10m 20s \t   113792 subphrases\n",
      "|     10m 20s \tfeatures from verses\n",
      "|     10m 20s \t    23213 verses\n",
      "|     10m 20s book names ...\n",
      "..............................................................................................\n",
      ".     10m 20s write data set to TF ...                                                       .\n",
      "..............................................................................................\n",
      "   |     0.04s T book                 to /Users/dirk/github/etcbc/bhsa/_temp/c/tf\n",
      "   |     0.00s T book@am              to /Users/dirk/github/etcbc/bhsa/_temp/c/tf\n",
      "   |     0.00s T book@ar              to /Users/dirk/github/etcbc/bhsa/_temp/c/tf\n",
      "   |     0.00s T book@bn              to /Users/dirk/github/etcbc/bhsa/_temp/c/tf\n",
      "   |     0.00s T book@da              to /Users/dirk/github/etcbc/bhsa/_temp/c/tf\n",
      "   |     0.00s T book@de              to /Users/dirk/github/etcbc/bhsa/_temp/c/tf\n",
      "   |     0.00s T book@el              to /Users/dirk/github/etcbc/bhsa/_temp/c/tf\n",
      "   |     0.00s T book@en              to /Users/dirk/github/etcbc/bhsa/_temp/c/tf\n",
      "   |     0.00s T book@es              to /Users/dirk/github/etcbc/bhsa/_temp/c/tf\n",
      "   |     0.00s T book@fa              to /Users/dirk/github/etcbc/bhsa/_temp/c/tf\n",
      "   |     0.00s T book@fr              to /Users/dirk/github/etcbc/bhsa/_temp/c/tf\n",
      "   |     0.00s T book@he              to /Users/dirk/github/etcbc/bhsa/_temp/c/tf\n",
      "   |     0.00s T book@hi              to /Users/dirk/github/etcbc/bhsa/_temp/c/tf\n",
      "   |     0.00s T book@id              to /Users/dirk/github/etcbc/bhsa/_temp/c/tf\n",
      "   |     0.00s T book@ja              to /Users/dirk/github/etcbc/bhsa/_temp/c/tf\n",
      "   |     0.00s T book@ko              to /Users/dirk/github/etcbc/bhsa/_temp/c/tf\n",
      "   |     0.00s T book@la              to /Users/dirk/github/etcbc/bhsa/_temp/c/tf\n",
      "   |     0.00s T book@nl              to /Users/dirk/github/etcbc/bhsa/_temp/c/tf\n",
      "   |     0.00s T book@pa              to /Users/dirk/github/etcbc/bhsa/_temp/c/tf\n",
      "   |     0.00s T book@pt              to /Users/dirk/github/etcbc/bhsa/_temp/c/tf\n",
      "   |     0.00s T book@ru              to /Users/dirk/github/etcbc/bhsa/_temp/c/tf\n",
      "   |     0.00s T book@sw              to /Users/dirk/github/etcbc/bhsa/_temp/c/tf\n",
      "   |     0.00s T book@syc             to /Users/dirk/github/etcbc/bhsa/_temp/c/tf\n",
      "   |     0.00s T book@tr              to /Users/dirk/github/etcbc/bhsa/_temp/c/tf\n",
      "   |     0.00s T book@ur              to /Users/dirk/github/etcbc/bhsa/_temp/c/tf\n",
      "   |     0.00s T book@yo              to /Users/dirk/github/etcbc/bhsa/_temp/c/tf\n",
      "   |     0.00s T book@zh              to /Users/dirk/github/etcbc/bhsa/_temp/c/tf\n",
      "   |     0.10s T chapter              to /Users/dirk/github/etcbc/bhsa/_temp/c/tf\n",
      "   |     0.17s T code                 to /Users/dirk/github/etcbc/bhsa/_temp/c/tf\n",
      "   |     0.93s T det                  to /Users/dirk/github/etcbc/bhsa/_temp/c/tf\n",
      "   |     1.31s T dist                 to /Users/dirk/github/etcbc/bhsa/_temp/c/tf\n",
      "   |     1.01s T dist_unit            to /Users/dirk/github/etcbc/bhsa/_temp/c/tf\n",
      "   |     0.19s T domain               to /Users/dirk/github/etcbc/bhsa/_temp/c/tf\n",
      "   |     0.48s T function             to /Users/dirk/github/etcbc/bhsa/_temp/c/tf\n",
      "   |     0.90s T g_cons               to /Users/dirk/github/etcbc/bhsa/_temp/c/tf\n",
      "   |     0.85s T g_cons_utf8          to /Users/dirk/github/etcbc/bhsa/_temp/c/tf\n",
      "   |     0.79s T g_lex                to /Users/dirk/github/etcbc/bhsa/_temp/c/tf\n",
      "   |     0.89s T g_lex_utf8           to /Users/dirk/github/etcbc/bhsa/_temp/c/tf\n",
      "   |     0.74s T g_nme                to /Users/dirk/github/etcbc/bhsa/_temp/c/tf\n",
      "   |     0.80s T g_nme_utf8           to /Users/dirk/github/etcbc/bhsa/_temp/c/tf\n",
      "   |     0.71s T g_pfm                to /Users/dirk/github/etcbc/bhsa/_temp/c/tf\n",
      "   |     0.72s T g_pfm_utf8           to /Users/dirk/github/etcbc/bhsa/_temp/c/tf\n",
      "   |     0.73s T g_prs                to /Users/dirk/github/etcbc/bhsa/_temp/c/tf\n",
      "   |     0.71s T g_prs_utf8           to /Users/dirk/github/etcbc/bhsa/_temp/c/tf\n",
      "   |     0.70s T g_uvf                to /Users/dirk/github/etcbc/bhsa/_temp/c/tf\n",
      "   |     0.72s T g_uvf_utf8           to /Users/dirk/github/etcbc/bhsa/_temp/c/tf\n",
      "   |     0.70s T g_vbe                to /Users/dirk/github/etcbc/bhsa/_temp/c/tf\n",
      "   |     0.75s T g_vbe_utf8           to /Users/dirk/github/etcbc/bhsa/_temp/c/tf\n",
      "   |     0.77s T g_vbs                to /Users/dirk/github/etcbc/bhsa/_temp/c/tf\n",
      "   |     0.94s T g_vbs_utf8           to /Users/dirk/github/etcbc/bhsa/_temp/c/tf\n",
      "   |     0.79s T g_voc_lex            to /Users/dirk/github/etcbc/bhsa/_temp/c/tf\n",
      "   |     0.82s T g_voc_lex_utf8       to /Users/dirk/github/etcbc/bhsa/_temp/c/tf\n",
      "   |     0.79s T g_word               to /Users/dirk/github/etcbc/bhsa/_temp/c/tf\n",
      "   |     0.82s T g_word_utf8          to /Users/dirk/github/etcbc/bhsa/_temp/c/tf\n",
      "   |     0.77s T gn                   to /Users/dirk/github/etcbc/bhsa/_temp/c/tf\n",
      "   |     0.17s T is_root              to /Users/dirk/github/etcbc/bhsa/_temp/c/tf\n",
      "   |     0.16s T kind                 to /Users/dirk/github/etcbc/bhsa/_temp/c/tf\n",
      "   |     0.12s T label                to /Users/dirk/github/etcbc/bhsa/_temp/c/tf\n",
      "   |     0.77s T language             to /Users/dirk/github/etcbc/bhsa/_temp/c/tf\n",
      "   |     0.80s T lex                  to /Users/dirk/github/etcbc/bhsa/_temp/c/tf\n",
      "   |     0.81s T lex_utf8             to /Users/dirk/github/etcbc/bhsa/_temp/c/tf\n",
      "   |     0.76s T ls                   to /Users/dirk/github/etcbc/bhsa/_temp/c/tf\n",
      "   |     0.36s T mother_object_type   to /Users/dirk/github/etcbc/bhsa/_temp/c/tf\n",
      "   |     0.75s T nme                  to /Users/dirk/github/etcbc/bhsa/_temp/c/tf\n",
      "   |     0.80s T nu                   to /Users/dirk/github/etcbc/bhsa/_temp/c/tf\n",
      "   |     2.34s T number               to /Users/dirk/github/etcbc/bhsa/_temp/c/tf\n",
      "   |     0.64s T otype                to /Users/dirk/github/etcbc/bhsa/_temp/c/tf\n",
      "   |     0.76s T pdp                  to /Users/dirk/github/etcbc/bhsa/_temp/c/tf\n",
      "   |     0.78s T pfm                  to /Users/dirk/github/etcbc/bhsa/_temp/c/tf\n",
      "   |     0.78s T prs                  to /Users/dirk/github/etcbc/bhsa/_temp/c/tf\n",
      "   |     0.81s T prs_gn               to /Users/dirk/github/etcbc/bhsa/_temp/c/tf\n",
      "   |     0.93s T prs_nu               to /Users/dirk/github/etcbc/bhsa/_temp/c/tf\n",
      "   |     0.79s T prs_ps               to /Users/dirk/github/etcbc/bhsa/_temp/c/tf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   |     0.95s T ps                   to /Users/dirk/github/etcbc/bhsa/_temp/c/tf\n",
      "   |     0.81s T qere                 to /Users/dirk/github/etcbc/bhsa/_temp/c/tf\n",
      "   |     0.72s T qere_utf8            to /Users/dirk/github/etcbc/bhsa/_temp/c/tf\n",
      "   |     1.38s T rela                 to /Users/dirk/github/etcbc/bhsa/_temp/c/tf\n",
      "   |     0.86s T sp                   to /Users/dirk/github/etcbc/bhsa/_temp/c/tf\n",
      "   |     0.77s T st                   to /Users/dirk/github/etcbc/bhsa/_temp/c/tf\n",
      "   |     0.16s T tab                  to /Users/dirk/github/etcbc/bhsa/_temp/c/tf\n",
      "   |     0.74s T trailer              to /Users/dirk/github/etcbc/bhsa/_temp/c/tf\n",
      "   |     0.75s T trailer_utf8         to /Users/dirk/github/etcbc/bhsa/_temp/c/tf\n",
      "   |     0.15s T txt                  to /Users/dirk/github/etcbc/bhsa/_temp/c/tf\n",
      "   |     1.24s T typ                  to /Users/dirk/github/etcbc/bhsa/_temp/c/tf\n",
      "   |     0.76s T uvf                  to /Users/dirk/github/etcbc/bhsa/_temp/c/tf\n",
      "   |     0.75s T vbe                  to /Users/dirk/github/etcbc/bhsa/_temp/c/tf\n",
      "   |     0.77s T vbs                  to /Users/dirk/github/etcbc/bhsa/_temp/c/tf\n",
      "   |     0.05s T verse                to /Users/dirk/github/etcbc/bhsa/_temp/c/tf\n",
      "   |     0.77s T vs                   to /Users/dirk/github/etcbc/bhsa/_temp/c/tf\n",
      "   |     0.81s T vt                   to /Users/dirk/github/etcbc/bhsa/_temp/c/tf\n",
      "   |     2.47s T distributional_parent to /Users/dirk/github/etcbc/bhsa/_temp/c/tf\n",
      "   |     3.94s T functional_parent    to /Users/dirk/github/etcbc/bhsa/_temp/c/tf\n",
      "   |     0.66s T mother               to /Users/dirk/github/etcbc/bhsa/_temp/c/tf\n",
      "   |     4.09s T oslots               to /Users/dirk/github/etcbc/bhsa/_temp/c/tf\n",
      "   |     0.00s M otext                to /Users/dirk/github/etcbc/bhsa/_temp/c/tf\n"
     ]
    }
   ],
   "source": [
    "tfFromData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................................................................................\n",
      ".     11m 25s Check differences with previous version                                        .\n",
      "..............................................................................................\n",
      "|     11m 25s \t2 features to add\n",
      "|     11m 25s \t\tg_voc_lex\n",
      "|     11m 25s \t\tg_voc_lex_utf8\n",
      "|     11m 25s \t14 features to delete\n",
      "|     11m 25s \t\tfreq_lex\n",
      "|     11m 25s \t\tfreq_occ\n",
      "|     11m 25s \t\tgloss\n",
      "|     11m 25s \t\tinstruction\n",
      "|     11m 25s \t\tlex0\n",
      "|     11m 25s \t\tnametype\n",
      "|     11m 25s \t\tpargr\n",
      "|     11m 25s \t\tqere_trailer\n",
      "|     11m 25s \t\tqere_trailer_utf8\n",
      "|     11m 25s \t\trank_lex\n",
      "|     11m 25s \t\trank_occ\n",
      "|     11m 25s \t\troot\n",
      "|     11m 25s \t\tvoc_lex\n",
      "|     11m 25s \t\tvoc_lex_utf8\n",
      "|     11m 25s \t93 features in common\n",
      "|     11m 25s book                      ... no changes\n",
      "|     11m 25s book@am                   ... no changes\n",
      "|     11m 25s book@ar                   ... no changes\n",
      "|     11m 25s book@bn                   ... no changes\n",
      "|     11m 25s book@da                   ... no changes\n",
      "|     11m 25s book@de                   ... no changes\n",
      "|     11m 25s book@el                   ... no changes\n",
      "|     11m 25s book@en                   ... no changes\n",
      "|     11m 25s book@es                   ... no changes\n",
      "|     11m 25s book@fa                   ... no changes\n",
      "|     11m 25s book@fr                   ... no changes\n",
      "|     11m 25s book@he                   ... no changes\n",
      "|     11m 25s book@hi                   ... no changes\n",
      "|     11m 25s book@id                   ... no changes\n",
      "|     11m 25s book@ja                   ... no changes\n",
      "|     11m 25s book@ko                   ... no changes\n",
      "|     11m 25s book@la                   ... no changes\n",
      "|     11m 25s book@nl                   ... no changes\n",
      "|     11m 25s book@pa                   ... no changes\n",
      "|     11m 25s book@pt                   ... no changes\n",
      "|     11m 25s book@ru                   ... no changes\n",
      "|     11m 25s book@sw                   ... no changes\n",
      "|     11m 25s book@syc                  ... no changes\n",
      "|     11m 25s book@tr                   ... no changes\n",
      "|     11m 25s book@ur                   ... no changes\n",
      "|     11m 25s book@yo                   ... no changes\n",
      "|     11m 25s book@zh                   ... no changes\n",
      "|     11m 25s chapter                   ... no changes\n",
      "|     11m 25s code                      ... no changes\n",
      "|     11m 25s det                       ... no changes\n",
      "|     11m 26s dist                      ... no changes\n",
      "|     11m 26s dist_unit                 ... no changes\n",
      "|     11m 27s distributional_parent     ... no changes\n",
      "|     11m 28s domain                    ... no changes\n",
      "|     11m 28s function                  ... no changes\n",
      "|     11m 28s functional_parent         ... no changes\n",
      "|     11m 29s g_cons                    ... no changes\n",
      "|     11m 30s g_cons_utf8               ... no changes\n",
      "|     11m 30s g_lex                     ... no changes\n",
      "|     11m 30s g_lex_utf8                ... no changes\n",
      "|     11m 31s g_nme                     ... no changes\n",
      "|     11m 31s g_nme_utf8                ... no changes\n",
      "|     11m 32s g_pfm                     ... no changes\n",
      "|     11m 32s g_pfm_utf8                ... no changes\n",
      "|     11m 32s g_prs                     ... no changes\n",
      "|     11m 33s g_prs_utf8                ... no changes\n",
      "|     11m 33s g_uvf                     ... no changes\n",
      "|     11m 34s g_uvf_utf8                ... no changes\n",
      "|     11m 34s g_vbe                     ... no changes\n",
      "|     11m 34s g_vbe_utf8                ... no changes\n",
      "|     11m 35s g_vbs                     ... no changes\n",
      "|     11m 35s g_vbs_utf8                ... no changes\n",
      "|     11m 35s g_word                    ... no changes\n",
      "|     11m 36s g_word_utf8               ... no changes\n",
      "|     11m 36s gn                        ... no changes\n",
      "|     11m 37s is_root                   ... no changes\n",
      "|     11m 37s kind                      ... no changes\n",
      "|     11m 37s label                     ... no changes\n",
      "|     11m 37s language                  ... differences after the metadata\n",
      "|     11m 37s \tline      2 OLD -->hbo<--\n",
      "|     11m 37s \tline      2 NEW -->Hebrew<--\n",
      "|     11m 37s \tline      3 OLD -->hbo<--\n",
      "|     11m 37s \tline      3 NEW -->Hebrew<--\n",
      "|     11m 37s \tline      4 OLD -->hbo<--\n",
      "|     11m 37s \tline      4 NEW -->Hebrew<--\n",
      "|     11m 37s \tline      5 OLD -->hbo<--\n",
      "|     11m 37s \tline      5 NEW -->Hebrew<--\n",
      "\n",
      "|     11m 37s lex                       ... differences after the metadata\n",
      "|     11m 37s \tline 426583 OLD -->1436895\tB<--\n",
      "|     11m 37s \tline 426583 NEW --><empty><--\n",
      "|     11m 37s \tline 426584 OLD -->R>CJT/<--\n",
      "|     11m 37s \tline 426584 NEW --><empty><--\n",
      "|     11m 37s \tline 426585 OLD -->BR>[<--\n",
      "|     11m 37s \tline 426585 NEW --><empty><--\n",
      "|     11m 37s \tline 426586 OLD -->>LHJM/<--\n",
      "|     11m 37s \tline 426586 NEW --><empty><--\n",
      "\n",
      "|     11m 37s lex_utf8                  ... differences after the metadata\n",
      "|     11m 38s \tline      3 OLD --><--\n",
      "|     11m 38s \tline      3 NEW --><--\n",
      "|     11m 38s \tline      5 OLD --><--\n",
      "|     11m 38s \tline      5 NEW --><--\n",
      "|     11m 38s \tline      8 OLD --><--\n",
      "|     11m 38s \tline      8 NEW --><--\n",
      "|     11m 38s \tline     12 OLD --><--\n",
      "|     11m 38s \tline     12 NEW --><--\n",
      "\n",
      "|     11m 38s ls                        ... differences after the metadata\n",
      "|     11m 38s \tline 426583 OLD -->1436904\tvbcp<--\n",
      "|     11m 38s \tline 426583 NEW --><empty><--\n",
      "|     11m 38s \tline 426584 OLD -->1436914\tquot<--\n",
      "|     11m 38s \tline 426584 NEW --><empty><--\n",
      "|     11m 38s \tline 426585 OLD -->1436920\tppre<--\n",
      "|     11m 38s \tline 426585 NEW --><empty><--\n",
      "|     11m 38s \tline 426586 OLD -->1436923\tpadv<--\n",
      "|     11m 38s \tline 426586 NEW --><empty><--\n",
      "\n",
      "|     11m 38s mother                    ... no changes\n",
      "|     11m 38s mother_object_type        ... no changes\n",
      "|     11m 38s nme                       ... no changes\n",
      "|     11m 39s nu                        ... no changes\n",
      "|     11m 39s number                    ... no changes\n",
      "|     11m 40s oslots                    ... differences after the metadata\n",
      "|     11m 42s \tline 1010315 OLD -->1,84,197,220,241,270,318,330,334,428,435 ...<--\n",
      "|     11m 42s \tline 1010315 NEW --><empty><--\n",
      "|     11m 42s \tline 1010316 OLD -->2,4662,27810,41330,48283,53076,66100,796 ...<--\n",
      "|     11m 42s \tline 1010316 NEW --><empty><--\n",
      "|     11m 42s \tline 1010317 OLD -->3,381,535,545,550,724,736,2126,2137,2148 ...<--\n",
      "|     11m 42s \tline 1010317 NEW --><empty><--\n",
      "|     11m 42s \tline 1010318 OLD -->4,26,34,42,50,60,81,97,127,142,162,176,1 ...<--\n",
      "|     11m 42s \tline 1010318 NEW --><empty><--\n",
      "\n",
      "|     11m 42s otext                     ... differences\n",
      "|     11m 42s \tline      5 OLD -->@dateWritten=2017-09-29T13:48:09Z<--\n",
      "|     11m 42s \tline      5 NEW -->@email=shebanq@ancient-data.org<--\n",
      "|     11m 42s \tline      6 OLD -->@email=shebanq@ancient-data.org<--\n",
      "|     11m 42s \tline      6 NEW -->@encoders=Constantijn Sikkel (QDF), Ulri ...<--\n",
      "|     11m 42s \tline      7 OLD -->@encoders=Constantijn Sikkel (QDF), Ulri ...<--\n",
      "|     11m 42s \tline      7 NEW -->@fmt:lex-orig-full={g_lex_utf8} <--\n",
      "|     11m 42s \tline      8 OLD -->@fmt:lex-orig-full={g_lex_utf8} <--\n",
      "|     11m 42s \tline      8 NEW -->@fmt:lex-orig-plain={lex_utf8} <--\n",
      "\n",
      "|     11m 42s otype                     ... differences after the metadata\n",
      "|     11m 42s \tline     14 OLD -->1436895-1446130\tlex<--\n",
      "|     11m 42s \tline     14 NEW --><empty><--\n",
      "\n",
      "|     11m 42s pdp                       ... no changes\n",
      "|     11m 42s pfm                       ... no changes\n",
      "|     11m 42s prs                       ... no changes\n",
      "|     11m 43s prs_gn                    ... no changes\n",
      "|     11m 43s prs_nu                    ... no changes\n",
      "|     11m 44s prs_ps                    ... no changes\n",
      "|     11m 44s ps                        ... no changes\n",
      "|     11m 45s qere                      ... differences after the metadata\n",
      "|     11m 45s \tline      2 OLD -->3897\tHAJ:Y;74><--\n",
      "|     11m 45s \tline      2 NEW --><--\n",
      "|     11m 45s \tline      3 OLD -->4420\t>@H:@LO75W<--\n",
      "|     11m 45s \tline      3 NEW --><--\n",
      "|     11m 45s \tline      4 OLD -->5645\t>@H:@LO92W<--\n",
      "|     11m 45s \tline      4 NEW --><--\n",
      "|     11m 45s \tline      5 OLD -->5912\t>@95H:@LOW03<--\n",
      "|     11m 45s \tline      5 NEW --><--\n",
      "\n",
      "|     11m 45s qere_utf8                 ... differences after the metadata\n",
      "|     11m 45s \tline      2 OLD -->3897\t<--\n",
      "|     11m 45s \tline      2 NEW --><--\n",
      "|     11m 45s \tline      3 OLD -->4420\t<--\n",
      "|     11m 45s \tline      3 NEW --><--\n",
      "|     11m 45s \tline      4 OLD -->5645\t<--\n",
      "|     11m 45s \tline      4 NEW --><--\n",
      "|     11m 45s \tline      5 OLD -->5912\t<--\n",
      "|     11m 45s \tline      5 NEW --><--\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|     11m 45s rela                      ... no changes\n",
      "|     11m 45s sp                        ... differences after the metadata\n",
      "|     11m 46s \tline 426583 OLD -->1436895\tprep<--\n",
      "|     11m 46s \tline 426583 NEW --><empty><--\n",
      "|     11m 46s \tline 426584 OLD -->subs<--\n",
      "|     11m 46s \tline 426584 NEW --><empty><--\n",
      "|     11m 46s \tline 426585 OLD -->verb<--\n",
      "|     11m 46s \tline 426585 NEW --><empty><--\n",
      "|     11m 46s \tline 426586 OLD -->subs<--\n",
      "|     11m 46s \tline 426586 NEW --><empty><--\n",
      "\n",
      "|     11m 46s st                        ... no changes\n",
      "|     11m 46s tab                       ... no changes\n",
      "|     11m 46s trailer                   ... no changes\n",
      "|     11m 47s trailer_utf8              ... no changes\n",
      "|     11m 47s txt                       ... no changes\n",
      "|     11m 47s typ                       ... no changes\n",
      "|     11m 48s uvf                       ... no changes\n",
      "|     11m 48s vbe                       ... no changes\n",
      "|     11m 49s vbs                       ... no changes\n",
      "|     11m 49s verse                     ... no changes\n",
      "|     11m 49s vs                        ... no changes\n",
      "|     11m 49s vt                        ... no changes\n",
      "|     11m 50s Done\n"
     ]
    }
   ],
   "source": [
    "utils.checkDiffs(thisTempTf, thisTf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................................................................................\n",
      ".     12m 04s Deliver data set to /Users/dirk/github/etcbc/bhsa/tf/c                         .\n",
      "..............................................................................................\n"
     ]
    }
   ],
   "source": [
    "utils.deliverDataset(thisTempTf, thisTf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................................................................................\n",
      ".     13m 20s Load and compile standard TF features                                          .\n",
      "..............................................................................................\n",
      "This is Text-Fabric 2.3.15\n",
      "Api reference : https://github.com/ETCBC/text-fabric/wiki/Api\n",
      "Tutorial      : https://github.com/ETCBC/text-fabric/blob/master/docs/tutorial.ipynb\n",
      "Data sources  : https://github.com/ETCBC/text-fabric-data\n",
      "\n",
      "95 features found and 0 ignored\n",
      "  0.00s loading features ...\n",
      "   |     0.79s T otype                from /Users/dirk/github/etcbc/bhsa/tf/c\n",
      "   |       10s T oslots               from /Users/dirk/github/etcbc/bhsa/tf/c\n",
      "   |     0.08s T book                 from /Users/dirk/github/etcbc/bhsa/tf/c\n",
      "   |     0.05s T chapter              from /Users/dirk/github/etcbc/bhsa/tf/c\n",
      "   |     0.05s T verse                from /Users/dirk/github/etcbc/bhsa/tf/c\n",
      "   |     1.44s T g_cons               from /Users/dirk/github/etcbc/bhsa/tf/c\n",
      "   |     1.77s T g_cons_utf8          from /Users/dirk/github/etcbc/bhsa/tf/c\n",
      "   |     1.52s T g_lex                from /Users/dirk/github/etcbc/bhsa/tf/c\n",
      "   |     1.69s T g_lex_utf8           from /Users/dirk/github/etcbc/bhsa/tf/c\n",
      "   |     1.60s T g_word               from /Users/dirk/github/etcbc/bhsa/tf/c\n",
      "   |     1.66s T g_word_utf8          from /Users/dirk/github/etcbc/bhsa/tf/c\n",
      "   |     1.44s T lex                  from /Users/dirk/github/etcbc/bhsa/tf/c\n",
      "   |     1.58s T lex_utf8             from /Users/dirk/github/etcbc/bhsa/tf/c\n",
      "   |     1.12s T trailer              from /Users/dirk/github/etcbc/bhsa/tf/c\n",
      "   |     1.15s T trailer_utf8         from /Users/dirk/github/etcbc/bhsa/tf/c\n",
      "   |      |     1.23s C __levels__           from otype, oslots\n",
      "   |      |       19s C __order__            from otype, oslots, __levels__\n",
      "   |      |     1.03s C __rank__             from otype, __order__\n",
      "   |      |       21s C __levUp__            from otype, oslots, __rank__\n",
      "   |      |       11s C __levDown__          from otype, __levUp__, __rank__\n",
      "   |      |     4.18s C __boundary__         from otype, oslots, __rank__\n",
      "   |     0.00s M otext                from /Users/dirk/github/etcbc/bhsa/tf/c\n",
      "   |      |     0.12s C __sections__         from otype, oslots, otext, __levUp__, __levels__, book, chapter, verse\n",
      "   |     0.00s T book@am              from /Users/dirk/github/etcbc/bhsa/tf/c\n",
      "   |     0.00s T book@ar              from /Users/dirk/github/etcbc/bhsa/tf/c\n",
      "   |     0.00s T book@bn              from /Users/dirk/github/etcbc/bhsa/tf/c\n",
      "   |     0.00s T book@da              from /Users/dirk/github/etcbc/bhsa/tf/c\n",
      "   |     0.00s T book@de              from /Users/dirk/github/etcbc/bhsa/tf/c\n",
      "   |     0.00s T book@el              from /Users/dirk/github/etcbc/bhsa/tf/c\n",
      "   |     0.00s T book@en              from /Users/dirk/github/etcbc/bhsa/tf/c\n",
      "   |     0.00s T book@es              from /Users/dirk/github/etcbc/bhsa/tf/c\n",
      "   |     0.00s T book@fa              from /Users/dirk/github/etcbc/bhsa/tf/c\n",
      "   |     0.00s T book@fr              from /Users/dirk/github/etcbc/bhsa/tf/c\n",
      "   |     0.00s T book@he              from /Users/dirk/github/etcbc/bhsa/tf/c\n",
      "   |     0.00s T book@hi              from /Users/dirk/github/etcbc/bhsa/tf/c\n",
      "   |     0.00s T book@id              from /Users/dirk/github/etcbc/bhsa/tf/c\n",
      "   |     0.00s T book@ja              from /Users/dirk/github/etcbc/bhsa/tf/c\n",
      "   |     0.00s T book@ko              from /Users/dirk/github/etcbc/bhsa/tf/c\n",
      "   |     0.00s T book@la              from /Users/dirk/github/etcbc/bhsa/tf/c\n",
      "   |     0.00s T book@nl              from /Users/dirk/github/etcbc/bhsa/tf/c\n",
      "   |     0.00s T book@pa              from /Users/dirk/github/etcbc/bhsa/tf/c\n",
      "   |     0.00s T book@pt              from /Users/dirk/github/etcbc/bhsa/tf/c\n",
      "   |     0.00s T book@ru              from /Users/dirk/github/etcbc/bhsa/tf/c\n",
      "   |     0.00s T book@sw              from /Users/dirk/github/etcbc/bhsa/tf/c\n",
      "   |     0.00s T book@syc             from /Users/dirk/github/etcbc/bhsa/tf/c\n",
      "   |     0.00s T book@tr              from /Users/dirk/github/etcbc/bhsa/tf/c\n",
      "   |     0.00s T book@ur              from /Users/dirk/github/etcbc/bhsa/tf/c\n",
      "   |     0.00s T book@yo              from /Users/dirk/github/etcbc/bhsa/tf/c\n",
      "   |     0.00s T book@zh              from /Users/dirk/github/etcbc/bhsa/tf/c\n",
      "   |     0.00s Feature overview: 90 for nodes; 4 for edges; 1 configs; 7 computed\n",
      " 1m 23s All features loaded/computed - for details use loadLog()\n",
      "..............................................................................................\n",
      ".     14m 43s Load and compile all other TF features                                         .\n",
      "..............................................................................................\n",
      "   |     0.00s Feature overview: 90 for nodes; 4 for edges; 1 configs; 7 computed\n",
      "  0.00s loading features ...\n",
      "   |     0.19s T code                 from /Users/dirk/github/etcbc/bhsa/tf/c\n",
      "   |     1.90s T det                  from /Users/dirk/github/etcbc/bhsa/tf/c\n",
      "   |     1.35s T dist                 from /Users/dirk/github/etcbc/bhsa/tf/c\n",
      "   |     2.12s T dist_unit            from /Users/dirk/github/etcbc/bhsa/tf/c\n",
      "   |     4.36s T distributional_parent from /Users/dirk/github/etcbc/bhsa/tf/c\n",
      "   |     0.29s T domain               from /Users/dirk/github/etcbc/bhsa/tf/c\n",
      "   |     1.10s T function             from /Users/dirk/github/etcbc/bhsa/tf/c\n",
      "   |     7.36s T functional_parent    from /Users/dirk/github/etcbc/bhsa/tf/c\n",
      "   |     1.00s T g_nme                from /Users/dirk/github/etcbc/bhsa/tf/c\n",
      "   |     1.10s T g_nme_utf8           from /Users/dirk/github/etcbc/bhsa/tf/c\n",
      "   |     0.80s T g_pfm                from /Users/dirk/github/etcbc/bhsa/tf/c\n",
      "   |     0.75s T g_pfm_utf8           from /Users/dirk/github/etcbc/bhsa/tf/c\n",
      "   |     0.81s T g_prs                from /Users/dirk/github/etcbc/bhsa/tf/c\n",
      "   |     0.89s T g_prs_utf8           from /Users/dirk/github/etcbc/bhsa/tf/c\n",
      "   |     0.71s T g_uvf                from /Users/dirk/github/etcbc/bhsa/tf/c\n",
      "   |     0.68s T g_uvf_utf8           from /Users/dirk/github/etcbc/bhsa/tf/c\n",
      "   |     0.93s T g_vbe                from /Users/dirk/github/etcbc/bhsa/tf/c\n",
      "   |     0.82s T g_vbe_utf8           from /Users/dirk/github/etcbc/bhsa/tf/c\n",
      "   |     0.74s T g_vbs                from /Users/dirk/github/etcbc/bhsa/tf/c\n",
      "   |     0.81s T g_vbs_utf8           from /Users/dirk/github/etcbc/bhsa/tf/c\n",
      "   |     1.92s T g_voc_lex            from /Users/dirk/github/etcbc/bhsa/tf/c\n",
      "   |     2.15s T g_voc_lex_utf8       from /Users/dirk/github/etcbc/bhsa/tf/c\n",
      "   |     1.87s T gn                   from /Users/dirk/github/etcbc/bhsa/tf/c\n",
      "   |     0.32s T is_root              from /Users/dirk/github/etcbc/bhsa/tf/c\n",
      "   |     0.33s T kind                 from /Users/dirk/github/etcbc/bhsa/tf/c\n",
      "   |     0.23s T label                from /Users/dirk/github/etcbc/bhsa/tf/c\n",
      "   |     1.52s T language             from /Users/dirk/github/etcbc/bhsa/tf/c\n",
      "   |     1.52s T ls                   from /Users/dirk/github/etcbc/bhsa/tf/c\n",
      "   |     0.89s T mother               from /Users/dirk/github/etcbc/bhsa/tf/c\n",
      "   |     0.71s T mother_object_type   from /Users/dirk/github/etcbc/bhsa/tf/c\n",
      "   |     1.30s T nme                  from /Users/dirk/github/etcbc/bhsa/tf/c\n",
      "   |     1.49s T nu                   from /Users/dirk/github/etcbc/bhsa/tf/c\n",
      "   |     2.76s T number               from /Users/dirk/github/etcbc/bhsa/tf/c\n",
      "   |     1.72s T pdp                  from /Users/dirk/github/etcbc/bhsa/tf/c\n",
      "   |     1.55s T pfm                  from /Users/dirk/github/etcbc/bhsa/tf/c\n",
      "   |     1.60s T prs                  from /Users/dirk/github/etcbc/bhsa/tf/c\n",
      "   |     1.67s T prs_gn               from /Users/dirk/github/etcbc/bhsa/tf/c\n",
      "   |     1.62s T prs_nu               from /Users/dirk/github/etcbc/bhsa/tf/c\n",
      "   |     1.62s T prs_ps               from /Users/dirk/github/etcbc/bhsa/tf/c\n",
      "   |     1.60s T ps                   from /Users/dirk/github/etcbc/bhsa/tf/c\n",
      "   |     0.72s T qere                 from /Users/dirk/github/etcbc/bhsa/tf/c\n",
      "   |     0.72s T qere_utf8            from /Users/dirk/github/etcbc/bhsa/tf/c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   |     2.60s T rela                 from /Users/dirk/github/etcbc/bhsa/tf/c\n",
      "   |     1.48s T sp                   from /Users/dirk/github/etcbc/bhsa/tf/c\n",
      "   |     1.38s T st                   from /Users/dirk/github/etcbc/bhsa/tf/c\n",
      "   |     0.18s T tab                  from /Users/dirk/github/etcbc/bhsa/tf/c\n",
      "   |     0.29s T txt                  from /Users/dirk/github/etcbc/bhsa/tf/c\n",
      "   |     2.53s T typ                  from /Users/dirk/github/etcbc/bhsa/tf/c\n",
      "   |     1.57s T uvf                  from /Users/dirk/github/etcbc/bhsa/tf/c\n",
      "   |     1.45s T vbe                  from /Users/dirk/github/etcbc/bhsa/tf/c\n",
      "   |     1.69s T vbs                  from /Users/dirk/github/etcbc/bhsa/tf/c\n",
      "   |     1.53s T vs                   from /Users/dirk/github/etcbc/bhsa/tf/c\n",
      "   |     1.54s T vt                   from /Users/dirk/github/etcbc/bhsa/tf/c\n",
      "   |     0.00s Feature overview: 90 for nodes; 4 for edges; 1 configs; 7 computed\n",
      " 1m 18s All features loaded/computed - for details use loadLog()\n",
      "..............................................................................................\n",
      ".     16m 02s Basic test                                                                     .\n",
      "..............................................................................................\n",
      "..............................................................................................\n",
      ".     16m 02s First verse in all formats                                                     .\n",
      "..............................................................................................\n",
      "lex-orig-full\n",
      "\t           \n",
      "text-orig-plain\n",
      "\t       \n",
      "text-trans-plain\n",
      "\tBR>CJT BR> >LHJM >T HCMJM W>T H>RY00 \n",
      "lex-trans-plain\n",
      "\tB R>CJT/ BR>[ >LHJM/ >T H CMJM/ W >T H >RY/ \n",
      "text-orig-full\n",
      "\t       \n",
      "lex-orig-plain\n",
      "\t           \n",
      "lex-trans-full\n",
      "\tB.:- R;>CIJT B.@R@> >:ELOH >;T HA- C.@MAJ W:- >;T H@- >@REY \n",
      "text-trans-full\n",
      "\tB.:-R;>CI73JT B.@R@74> >:ELOHI92JM >;71T HA-C.@MA73JIM W:->;71T H@->@75REY00 \n"
     ]
    }
   ],
   "source": [
    "compileTfData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
